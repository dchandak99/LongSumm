{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import hashlib\n",
    "import subprocess\n",
    "import collections\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "import io\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('CLASSPATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['java', 'edu.stanford.nlp.process.PTBTokenizer',\n",
    "               '-ioFileList', '-preserveLines', '/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CLASSPATH=/home/devansh/Documents/EMNLP/stanford-corenlp-latest/stanford-corenlp-4.0.0/stanford-corenlp-4.0.0.jar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find or load main class edu.stanford.nlp.process.PTBTokenizer\r\n",
      "Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.process.PTBTokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"$(</home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation)\" | java edu.stanford.nlp.process.PTBTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find or load main class edu.stanford.nlp.process.PTBTokenizer\r\n",
      "Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.process.PTBTokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"Please tokenize this text.\" | java edu.stanford.nlp.process.PTBTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - posix\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/msys2/linux-64\n",
      "  - https://conda.anaconda.org/msys2/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c msys2 posix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashhex(s):\n",
    "    \"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"\n",
    "    h = hashlib.sha1()\n",
    "    h.update(s.encode())\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('out.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = list(map(lambda x: hashhex(x), lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outfile\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('The', '93ef0dd827103681fcee453b78be2ff14e1a261d'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('joint', 'da9dc2f54bcc987bbfaa8399451f7b0253e1382b'),\n",
       " ('model', '1d06a0d76f000e6edd18de492383983feefced4e'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('which', 'ed04ff4dabf1e2d4cd6b89136c2b24dec27ecca4'),\n",
       " ('augments', 'df6e09acb6e5a6012c8a3f7adc39e461ea3d9be4'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('language', 'e11523c5ff23fc1600aca2d8ee5adb542c5ce4b3'),\n",
       " ('model', '1d06a0d76f000e6edd18de492383983feefced4e'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('NNLM', '19e70e4b37daad9e8664227a48457488a4ee19d5'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('an', 'de73eac0c305038f0437bc6a1f994a5a4379ed28'),\n",
       " ('m', '6b0d31c0d563223024da45691584643ac78c96e8'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('source', '828d338a9b04221c9cbe286f50cd389f68de4ecf'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('window', '320ad267d8d969f285eda5c184f5455bd29c8c95'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('has', 'f6f39fbf678d4c03ca72f7d0c7b4f56fb09eb765'),\n",
       " ('achieved', '5f7ddc4a248c6225ac3ebbd14e78575d86fde305'),\n",
       " ('large', '5296d5cced2aa1cf19afd9cf498d89f0d85481f2'),\n",
       " ('gains', '8c5985719ad0936764f374d5938ede9f90b98085'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('machine', '7817c52b25607be67ce93c0e5e7081fb6a2346f2'),\n",
       " ('translation', 'efd7fd7f2954713c1ee7facf9750fe53e8cf589c'),\n",
       " ('accuracy', '26de05a44d1e5fe8d199a0b207cf89f9e390f7dd'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('but', '786e97b3ee9fc4b292d5852c2c5943153c4ce91a'),\n",
       " ('also', '09706c418809f1f4cfda992435ca1438eddaaeed'),\n",
       " ('has', 'f6f39fbf678d4c03ca72f7d0c7b4f56fb09eb765'),\n",
       " ('problems', 'd6d2076ce386d1067b4e51b784fb2b9bdd3e692e'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('high', '9235afd3e98802411861a961aa9cf61e90c1c977'),\n",
       " ('normalization', '55ba1d472f08876b44dea01ba35de467949b0230'),\n",
       " ('cost', '885dc4a9b362094fb138a3d17c4933bf3e8b9d85'),\n",
       " ('when', '30603fa9e0f620c305cd627ab0ff138a960c48bd'),\n",
       " ('using', '92bd75ebd8fd2b0179172217b15350cc6d4002f0'),\n",
       " ('large', '5296d5cced2aa1cf19afd9cf498d89f0d85481f2'),\n",
       " ('vocabularies', '9cfce17ddad24f69efcd3624f8940485fe4a3876'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Training', 'b6fe7f5e79177b05f6d251ecb9c162d45455045d'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('contrastive', 'cf5a127b39d2e5dac8f500ad1c4b0c47df38008e'),\n",
       " ('estimation', '6fae58757e16134562ad327309dc715500e0ca48'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('instead', '571d5bc739cc9f7bbab15b2de12fe6c2903c98a9'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('standard', 'f410e0466ae4b065bfa4d9010ad6056864ed4e50'),\n",
       " ('maximum', 'e77a31599e99d15e380047e8783cdf95abc7d2b4'),\n",
       " ('likelihood', 'b4f899713e792e9cbb273d345f93d9f3123fa141'),\n",
       " ('estimation', '6fae58757e16134562ad327309dc715500e0ca48'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('MLE', '5271b723b719259d50134696d371b560e1683abf'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('reduce', '48c3689f6dd5e9e952f925b7ebebf64d7c43fc56'),\n",
       " ('computation', 'b3ce1e6c61013449eef07bc7c4a45b0c16f84ece'),\n",
       " ('cost', '885dc4a9b362094fb138a3d17c4933bf3e8b9d85'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('In', 'aef36502d67b0520654deb764dd055a7e905cfdd'),\n",
       " ('this', 'c2543fff3bfa6f144c2f06a7de6cd10c0b650cae'),\n",
       " ('paper', '950593b1f42de841169aa7d59486b7e980bc15cf'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('we', '676e6f35cfc173f73fea9fe27699cf8185397f0c'),\n",
       " ('propose', '5fc6bd935d507d3379252a827a7a318114cc9ce0'),\n",
       " ('an', 'de73eac0c305038f0437bc6a1f994a5a4379ed28'),\n",
       " ('alternative', '816d63e63c53fbbcdc73b605731fb850111597ab'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('binarized', '33e66ffd1ce278b55702d1eca24f1e3fda34630b'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('which', 'ed04ff4dabf1e2d4cd6b89136c2b24dec27ecca4'),\n",
       " ('learns', 'f8ad9164e162f616053a9ea455d886f9a0b00e44'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('binary', '7e57cfe843145135aee1f4d0d63ceb7842093712'),\n",
       " ('classifier', '49061e96f40a33a23aa888e4a796825e63255147'),\n",
       " ('that', '33b82201081ec7c438cb5d9a36cd72bcb153050b'),\n",
       " ('takes', '69e0d06ab21edcdf51b0dd586201386a3868c006'),\n",
       " ('both', 'fc39b18f287d8bbfaceae020f4a4eb32ac5c1e70'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('input', '140f86aae51ab9e1cda9b4254fe98a74eb54c1a1'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('efficiently', '5273df4f0624d7297b424c16cdc30f8d3c6762f2'),\n",
       " ('trained', 'f7f599e6b44c44fa168819ac6c8b2c914583c62b'),\n",
       " ('using', '92bd75ebd8fd2b0179172217b15350cc6d4002f0'),\n",
       " ('MLE', '5271b723b719259d50134696d371b560e1683abf'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('We', 'a24ae9faf6a4ba419bee6dc5d1d746acf826b198'),\n",
       " ('compare', 'b64ca250f492e3f0444ad32b68be5f60a163bede'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('trained', 'f7f599e6b44c44fa168819ac6c8b2c914583c62b'),\n",
       " ('by', '408158643ed564c72fa0921826f8294d71ccbf7c'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " ('on', 'db3d405b10675998c030223177d42e71b4e7a312'),\n",
       " ('various', '7942c90e546d25e45ba0083880f25c87af654f0e'),\n",
       " ('translation', 'efd7fd7f2954713c1ee7facf9750fe53e8cf589c'),\n",
       " ('tasks', '55d8727a05eb80b0788af57a5317f3e0a1f4aa55'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Introduction', '2473e96bc614a911821242119918a241a41836d6'),\n",
       " ('Neural', '69ad5545653efa947045addb19c4393642df2a2e'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('translation', 'efd7fd7f2954713c1ee7facf9750fe53e8cf589c'),\n",
       " ('models', '5ba2688dffd71df813a468578a87c653e1575e1e'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('which', 'ed04ff4dabf1e2d4cd6b89136c2b24dec27ecca4'),\n",
       " ('learn', '7dca5d4cddf5fa5de51b357b937a5fc6b5c63660'),\n",
       " ('mappings', 'f5b465b16b24ffb0fcef00b86b8635439206dbb5'),\n",
       " ('over', 'f0fed7e4932302916b4e9c73fe47edcafeed7c44'),\n",
       " ('real', 'c9c64e071d2853bc7906c017a231ad1cc46ab630'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('valued', '227f407089e93419522c47a6f2dd2db7e4224dc0'),\n",
       " ('vector', '027c1146b1b8f9274e5a4cfd7a959e328a326cd6'),\n",
       " ('representations', '487a661beaed6d2d8717a36f070418057895226d'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('high', '9235afd3e98802411861a961aa9cf61e90c1c977'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('dimensional', '28c19ce4e9ddc9168621f8ebb05a2a953c2dfd10'),\n",
       " ('space', '0803df4ff1650933d2ffe6be04d4b21432134252'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('have', 'ff87cea4a48b77342a2dbef29133a128abc52679'),\n",
       " ('recently', 'fd92cc8545a9475c9b73ede831aa6a4ab4235677'),\n",
       " ('achieved', '5f7ddc4a248c6225ac3ebbd14e78575d86fde305'),\n",
       " ('large', '5296d5cced2aa1cf19afd9cf498d89f0d85481f2'),\n",
       " ('gains', '8c5985719ad0936764f374d5938ede9f90b98085'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('translation', 'efd7fd7f2954713c1ee7facf9750fe53e8cf589c'),\n",
       " ('accuracy', '26de05a44d1e5fe8d199a0b207cf89f9e390f7dd'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('Hu', 'c00340528b1123868d94af23636c7e2e86027c21'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (';', '2d14ab97cc3dc294c51c0d6814f4ea45f4b4e312'),\n",
       " ('Devlin', '6019c3112e8a4477fcea9a984a124e3fc2cce288'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (';', '2d14ab97cc3dc294c51c0d6814f4ea45f4b4e312'),\n",
       " ('Sundermeyer', '88a32ee6512afaee8ee2b62c8769ff8b77d67263'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (';', '2d14ab97cc3dc294c51c0d6814f4ea45f4b4e312'),\n",
       " ('Auli', 'a37f32367813266528fabb308bdce04e83d4e672'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2013', 'd08b10a32612f9d3bc06be41124becfd39536eee'),\n",
       " (';', '2d14ab97cc3dc294c51c0d6814f4ea45f4b4e312'),\n",
       " ('Schwenk', '60de699b2647c45ed6cee0a97d1246e7b6196b09'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2012', '084b3af47af339166ebc6120a52059499a7b2d38'),\n",
       " (';', '2d14ab97cc3dc294c51c0d6814f4ea45f4b4e312'),\n",
       " ('Sutskever', '049ba761e275bf02ccd743371a0041f32e9ff291'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (';', '2d14ab97cc3dc294c51c0d6814f4ea45f4b4e312'),\n",
       " ('Bahdanau', 'ecb8bb4dace477af046e36a23e57edfae65d4557'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2015', '9cdda67ded3f25811728276cefa76b80913b4c54'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Notably', '8f6707bd05090bdaea0fea00f418965e10d1e143'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('Devlin', '6019c3112e8a4477fcea9a984a124e3fc2cce288'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('proposed', '022624c0f29cf1cc332b7953322e0ba7ba09b2d3'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('joint', 'da9dc2f54bcc987bbfaa8399451f7b0253e1382b'),\n",
       " ('model', '1d06a0d76f000e6edd18de492383983feefced4e'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('which', 'ed04ff4dabf1e2d4cd6b89136c2b24dec27ecca4'),\n",
       " ('augments', 'df6e09acb6e5a6012c8a3f7adc39e461ea3d9be4'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('n', 'd1854cae891ec7b29161ccaf79a24b00c274bdaa'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('gram', '58d67c9d43cfd11d143550c5db5576ccfb75762d'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('language', 'e11523c5ff23fc1600aca2d8ee5adb542c5ce4b3'),\n",
       " ('model', '1d06a0d76f000e6edd18de492383983feefced4e'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('NNLM', '19e70e4b37daad9e8664227a48457488a4ee19d5'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('an', 'de73eac0c305038f0437bc6a1f994a5a4379ed28'),\n",
       " ('m', '6b0d31c0d563223024da45691584643ac78c96e8'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('source', '828d338a9b04221c9cbe286f50cd389f68de4ecf'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('window', '320ad267d8d969f285eda5c184f5455bd29c8c95'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('shown', '552a9a57db099fc652df882729e7224ff9dd8c55'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('Figure', '1f20e66b17a6eb7c2baf1ab68337d91eaf6f4f80'),\n",
       " ('1a', '9b2c3280ccea0ba408270c45185bfbcd36164237'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('While', 'd86a5675cc6478e7030415aaa83cd72801292548'),\n",
       " ('this', 'c2543fff3bfa6f144c2f06a7de6cd10c0b650cae'),\n",
       " ('model', '1d06a0d76f000e6edd18de492383983feefced4e'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('effective', 'da225248d262d3387dbe42977e59584810da571c'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('computation', 'b3ce1e6c61013449eef07bc7c4a45b0c16f84ece'),\n",
       " ('cost', '885dc4a9b362094fb138a3d17c4933bf3e8b9d85'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('using', '92bd75ebd8fd2b0179172217b15350cc6d4002f0'),\n",
       " ('it', '6c5522ca8af86fc5069b737bb8892b3ea61002c2'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('large', '5296d5cced2aa1cf19afd9cf498d89f0d85481f2'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('vocabulary', '21861253d6fcd033c2f88da079e5750db84da93e'),\n",
       " ('SMT', 'ba42eddff929d66d0517e9ab8834def39b6e42d1'),\n",
       " ('task', '7fbb727db4b2b6715b092505673cb5922a0d63a8'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('quite', '5898102702f118870028aae25a26f24e32303248'),\n",
       " ('expensive', 'e0d587ce038c01af32b4e03e5c7dfbafcc2b75bc'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('probabilities', '9d5fa0825055a7fad184227e60ccdc62238f31fd'),\n",
       " ('need', 'efe30e310694de6b40db25e0bb3b5aa8b0c2b976'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('normalized', '6d434ccaed805b0aaee07a9f4ba551a541303d01'),\n",
       " ('over', 'f0fed7e4932302916b4e9c73fe47edcafeed7c44'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('entire', '747761a820ea0860b14fc6679787e58916623a88'),\n",
       " ('vocabulary', '21861253d6fcd033c2f88da079e5750db84da93e'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('To', 'ae79ea1e9c6391a9ed83a2e18a031b835feec0c9'),\n",
       " ('solve', 'f544e4c95b06b4e32b2282aa76a3e1d4063fbeb7'),\n",
       " ('this', 'c2543fff3bfa6f144c2f06a7de6cd10c0b650cae'),\n",
       " ('problem', 'a5a0d15d4ae8ea37884d2fb9d8a30fbfc96731f3'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('Devlin', '6019c3112e8a4477fcea9a984a124e3fc2cce288'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('presented', '6a3188d9ee4ea210286f94e1561538de58de3765'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('technique', 'b41c6aff6d5da9bbcdc32f75c3fbe2009cdd6ed8'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('train', '94efdd6f628eda9c1ae893467c9652808443ef3e'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('selfnormalized', 'b082e5370ea8148c23e2b2a4d0e720b1a1df740f'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('avoided', 'e665083f470fea4b2da577294fa510a35280c281'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('expensive', 'e0d587ce038c01af32b4e03e5c7dfbafcc2b75bc'),\n",
       " ('normalization', '55ba1d472f08876b44dea01ba35de467949b0230'),\n",
       " ('cost', '885dc4a9b362094fb138a3d17c4933bf3e8b9d85'),\n",
       " ('during', 'ffed391ca2a6c8bb0b20f95bace87ef78d0c9f59'),\n",
       " ('decoding', 'a54087722f66e2368393bda323a8221081256b47'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('However', '1c9d9af883f45d80f6eff44c5cc66e4e9b4d5a21'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('they', 'f1fdd46d8d229558fa889e1610ec4ca9adc25328'),\n",
       " ('also', '09706c418809f1f4cfda992435ca1438eddaaeed'),\n",
       " ('note', 'c51048b7325d60e326d19a9cfbeff2577be1672e'),\n",
       " ('that', '33b82201081ec7c438cb5d9a36cd72bcb153050b'),\n",
       " ('this', 'c2543fff3bfa6f144c2f06a7de6cd10c0b650cae'),\n",
       " ('self', '40380bc1d358a6f8665b37bbdc8c7ccc6c38a861'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('normalization', '55ba1d472f08876b44dea01ba35de467949b0230'),\n",
       " ('technique', 'b41c6aff6d5da9bbcdc32f75c3fbe2009cdd6ed8'),\n",
       " ('sacrifices', 'c3131e560534413209e1a91861a083ece16ba1e4'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('accuracy', '26de05a44d1e5fe8d199a0b207cf89f9e390f7dd'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('training', '0a2b9827e548969e4dfe1b0d16c072ef347836d6'),\n",
       " ('process', 'c2e2d6621334dc890bbd8a69430012c45a83bf65'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('self', '40380bc1d358a6f8665b37bbdc8c7ccc6c38a861'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('normalized', '6d434ccaed805b0aaee07a9f4ba551a541303d01'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('very', 'e74295bfc2ed0b52d40073e8ebad555100df1380'),\n",
       " ('slow', '57e8a7776d6892a83f2a49678f8141f4fb883e62'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('standard', 'f410e0466ae4b065bfa4d9010ad6056864ed4e50'),\n",
       " ('maximum', 'e77a31599e99d15e380047e8783cdf95abc7d2b4'),\n",
       " ('likelihood', 'b4f899713e792e9cbb273d345f93d9f3123fa141'),\n",
       " ('estimation', '6fae58757e16134562ad327309dc715500e0ca48'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('MLE', '5271b723b719259d50134696d371b560e1683abf'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('To', 'ae79ea1e9c6391a9ed83a2e18a031b835feec0c9'),\n",
       " ('remedy', '201bd9db24d5342ca938e5ae6438889943f04521'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('problem', 'a5a0d15d4ae8ea37884d2fb9d8a30fbfc96731f3'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('long', 'bd3027fa569ea15ca76d84db21c67e2d514c1a5a'),\n",
       " ('training', '0a2b9827e548969e4dfe1b0d16c072ef347836d6'),\n",
       " ('times', '7196b5875f713c826bd279dbda843c897e2a60c2'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('NNLMs', 'b8b98807fc2a11cd39e60f5ef9d6e92da8e89388'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('Vaswani', '521499abcabf9575e6d8bc9d443b1a7f2c0616e0'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('2013', 'd08b10a32612f9d3bc06be41124becfd39536eee'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('used', '192a56759d36454cc0b8c812e31845e9ed10b130'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('method', 'bfbaf8b2d1cdf92bf83857fe1748c0f68de03d47'),\n",
       " ('called', '970eeb47b2d091dc3fee38f7ecd0e8ec3352f34f'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('contrastive', 'cf5a127b39d2e5dac8f500ad1c4b0c47df38008e'),\n",
       " ('estimation', '6fae58757e16134562ad327309dc715500e0ca48'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Compared', '31cb72792b806ff074123f4403021402bad47b0b'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('MLE', '5271b723b719259d50134696d371b560e1683abf'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " ('does', 'f0d521a5dc37493901c869e3f3753ee3ac06b9c0'),\n",
       " ('not', '557f255516719ea16f8f4a0aae1166054e2c9b43'),\n",
       " ('require', '623e76c36aa2a886542011e28412cc761d7ceb01'),\n",
       " ('repeated', 'ff9a06bdac561a30eb6a8815c8062577ac5c5597'),\n",
       " ('summations', 'e71896ea272e3a452dd3a6ea74817d9d53207ceb'),\n",
       " ('over', 'f0fed7e4932302916b4e9c73fe47edcafeed7c44'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('whole', 'af81132610ec21451a6b9d3a0acfb847ea155c9f'),\n",
       " ('vocabulary', '21861253d6fcd033c2f88da079e5750db84da93e'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('performs', '0601230d5a588dca2ef7dc18f75bd8ed1275bfcb'),\n",
       " ('nonlinear', '8d514444af89bd7e5a6d5541d97199f1b66e5795'),\n",
       " ('logistic', '3d70cca14cc3b2d32e6f822ff22bd55a029b551f'),\n",
       " ('regression', 'ea585073ff8843ad70c48735f623e8440e73cd57'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('discriminate', '7db58c62563502a71ec1662df03f836bf9542b45'),\n",
       " ('between', '709634051471385aada32356842983beeff4b065'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('observed', 'eb6e74ca6cfe960595a0e3866343993d1d2cb8e3'),\n",
       " ('data', 'a17c9aaa61e80a1bf71d0d850af4e5baa9800bbd'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('artificially', '5fe8a8bfeed30d71e84a979ea2b49775fd6f504d'),\n",
       " ('generated', '67bd5810ec8162548419905bc9769ccf95fe3a1f'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('This', '7971e6a051104074fdae0f02322417b6eb5695a2'),\n",
       " ('paper', '950593b1f42de841169aa7d59486b7e980bc15cf'),\n",
       " ('proposes', 'ac5ab33f6ee0474e892c9de6813161203cbd3700'),\n",
       " ('an', 'de73eac0c305038f0437bc6a1f994a5a4379ed28'),\n",
       " ('alternative', '816d63e63c53fbbcdc73b605731fb850111597ab'),\n",
       " ('framework', 'f178867da2879cae0f60630a6a2da174e0c2328e'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('binarized', '33e66ffd1ce278b55702d1eca24f1e3fda34630b'),\n",
       " ('NNJMs', 'bad36b8769ed2c84df39d3f187b2c389d9487fc4'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('which', 'ed04ff4dabf1e2d4cd6b89136c2b24dec27ecca4'),\n",
       " ('are', '5f9e5802bbabc71f9275fccf122f5a52b8599f12'),\n",
       " ('similar', 'af62f3021051fbc94ca3634d2fb20f27def55853'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('but', '786e97b3ee9fc4b292d5852c2c5943153c4ce91a'),\n",
       " ('use', '04489a12bbaa6aebffb61ed2f524424ba8e1147e'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('current', '405ab5d2b930fe3725b3cb1ace051f9fd3d6d7af'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('not', '557f255516719ea16f8f4a0aae1166054e2c9b43'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('output', '1029d67644815d428f554e390aa966d57a0b29b8'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('but', '786e97b3ee9fc4b292d5852c2c5943153c4ce91a'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('input', '140f86aae51ab9e1cda9b4254fe98a74eb54c1a1'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('estimating', '9f0136186a99f30b54fa0d0931eb27b04eb1a884'),\n",
       " ('whether', '3b959693d09b2240ecc5112647d33a2a66c14aa2'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('under', 'dad64cc6f975d048a78e4283720db3e86293ca8e'),\n",
       " ('examination', '36d2b0a31a6434ea9640e990e40e53986ef94c04'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('correct', '3179a65eff2523bbde53c99b299b719c10a35235'),\n",
       " ('or', '1758356db21759f7c5a0da9b4dd1db8fd6feab3f'),\n",
       " ('not', '557f255516719ea16f8f4a0aae1166054e2c9b43'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('shown', '552a9a57db099fc652df882729e7224ff9dd8c55'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('Figure', '1f20e66b17a6eb7c2baf1ab68337d91eaf6f4f80'),\n",
       " ('1b', '2d91a20a20fcaeb0ae60b5189b810bdf8481b1d7'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Because', 'eaebe47425c9f545a41d705608612a34bef824ca'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " ('uses', 'a7e2c648dc9941f38aea4196f90df226d6e93b2b'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('current', '405ab5d2b930fe3725b3cb1ace051f9fd3d6d7af'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('input', '140f86aae51ab9e1cda9b4254fe98a74eb54c1a1'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('information', '83dd9d6af43f8cbee08acd981417321e144b776b'),\n",
       " ('about', '5780daf6db0b013dbf82807c9f85abba683b0820'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('current', '405ab5d2b930fe3725b3cb1ace051f9fd3d6d7af'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('combined', 'bd902042faadd0f0eedc0fccd472ca0b441d088f'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('information', '83dd9d6af43f8cbee08acd981417321e144b776b'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('processed', '46c7abc90975bad7d134920630ac021d738d4aa2'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('hidden', '99d72c7fc3e2e145870beab37c0b70e343ea9c3b'),\n",
       " ('layers', '668165d561c62f330e96b629c4cdbaaa6a959900'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('The', '93ef0dd827103681fcee453b78be2ff14e1a261d'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " ('learns', 'f8ad9164e162f616053a9ea455d886f9a0b00e44'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('simple', '0f7d0d088b6ea936fb25b477722d734706fe8b40'),\n",
       " ('binary', '7e57cfe843145135aee1f4d0d63ceb7842093712'),\n",
       " ('classifier', '49061e96f40a33a23aa888e4a796825e63255147'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('given', '1d71315e40d788175324082b08aeee624501f8d5'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('therefore', '012071d7359274e1a5fbc5e2ee15872cff56c932'),\n",
       " ('it', '6c5522ca8af86fc5069b737bb8892b3ea61002c2'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('trained', 'f7f599e6b44c44fa168819ac6c8b2c914583c62b'),\n",
       " ('by', '408158643ed564c72fa0921826f8294d71ccbf7c'),\n",
       " ('MLE', '5271b723b719259d50134696d371b560e1683abf'),\n",
       " ('very', 'e74295bfc2ed0b52d40073e8ebad555100df1380'),\n",
       " ('efficiently', '5273df4f0624d7297b424c16cdc30f8d3c6762f2'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('\"', '2ace62c1befa19e3ea37dd52be9f6d508c5163e6'),\n",
       " ('Incorrect', '78318ed3e6ca4f2006eecd671fb4e1b78bbf85cb'),\n",
       " ('\"', '2ace62c1befa19e3ea37dd52be9f6d508c5163e6'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('generated', '67bd5810ec8162548419905bc9769ccf95fe3a1f'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('same', 'ff3390557335ba88d37755e41514beb03bc499ec'),\n",
       " ('way', 'ed36cbf2c9bb73ca445c18f5195c59b62495d89c'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " ('generates', '1c970930d4f953925a6ad107cd7edbbbc8765416'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('We', 'a24ae9faf6a4ba419bee6dc5d1d746acf826b198'),\n",
       " ('present', '50644481c7cd620b733fcc580e5d6745665dac74'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('novel', 'caee3e9d54b49ae50aa4ae7bbe306decdf2028aa'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('distribution', 'c6fbbcc823401b2122e8791c3e6ff154f83ff4ad'),\n",
       " ('based', '269f6e7dce9ef2c00cbe83df8e056fbe0c1099e2'),\n",
       " ('on', 'db3d405b10675998c030223177d42e71b4e7a312'),\n",
       " ('translation', 'efd7fd7f2954713c1ee7facf9750fe53e8cf589c'),\n",
       " ('probabilities', '9d5fa0825055a7fad184227e60ccdc62238f31fd'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('train', '94efdd6f628eda9c1ae893467c9652808443ef3e'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('BNNJM', '0fd73c1a3c36b3e79e7816be468642ff254a3699'),\n",
       " ('efficiently', '5273df4f0624d7297b424c16cdc30f8d3c6762f2'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Neural', '69ad5545653efa947045addb19c4393642df2a2e'),\n",
       " ('Network', '53ebc572b4a44802ba114729f07bdaaf5409a9d7'),\n",
       " ('Joint', 'e08e57447bc451c11bf4dd7d56173838cfb9b38b'),\n",
       " ('Model', '68c2cc7f0ceaa3e499ecb4db331feb4debbbcc23'),\n",
       " ('Let', 'ef5fe1edf37940bd463fee8eda068dc8d66b0f8a'),\n",
       " ('T', 'c2c53d66948214258a26ca9ca845d7ac0c17f8e7'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('T', 'c2c53d66948214258a26ca9ca845d7ac0c17f8e7'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('translation', 'efd7fd7f2954713c1ee7facf9750fe53e8cf589c'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('S', '02aa629c8b16cd17a44f3a0efec2feed43937642'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('s', 'a0f1490a20d0211c997b44bc357e1972deab8ae3'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('S', '02aa629c8b16cd17a44f3a0efec2feed43937642'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('The', '93ef0dd827103681fcee453b78be2ff14e1a261d'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('Devlin', '6019c3112e8a4477fcea9a984a124e3fc2cce288'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('defines', '039b47cbc9c0217b5f228e0aa810db4f44916629'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('following', '6cbf68c50f73c84678b2d08307c10e5dc93dd3c4'),\n",
       " ('probability', 'a88397b662aed68f19969442e49b6611b62c4794'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('P', '511993d3c99719e38a6779073019dacd7178ddb9'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('T', 'c2c53d66948214258a26ca9ca845d7ac0c17f8e7'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('S', '02aa629c8b16cd17a44f3a0efec2feed43937642'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('T', 'c2c53d66948214258a26ca9ca845d7ac0c17f8e7'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('P', '511993d3c99719e38a6779073019dacd7178ddb9'),\n",
       " ('ti', '41c76e5218177bb90eb3d29d24da7b418a07d440'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('s', 'a0f1490a20d0211c997b44bc357e1972deab8ae3'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('+', 'a979ef10cc6f6a36df6b8a323307ee3bb2e2db9c'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('m', '6b0d31c0d563223024da45691584643ac78c96e8'),\n",
       " ('−', '6a4e6e729f96b07652599ea183dcceac72cdf70f'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('/', '42099b4af021e53fd8fd4e056c2568d7c2e3ffa8'),\n",
       " ('2', 'da4b9237bacccdf19c0760cab7aec4a8359010b0'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('−', '6a4e6e729f96b07652599ea183dcceac72cdf70f'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('m', '6b0d31c0d563223024da45691584643ac78c96e8'),\n",
       " ('−', '6a4e6e729f96b07652599ea183dcceac72cdf70f'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('/', '42099b4af021e53fd8fd4e056c2568d7c2e3ffa8'),\n",
       " ('2', 'da4b9237bacccdf19c0760cab7aec4a8359010b0'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('−', '6a4e6e729f96b07652599ea183dcceac72cdf70f'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('−', '6a4e6e729f96b07652599ea183dcceac72cdf70f'),\n",
       " ('n', 'd1854cae891ec7b29161ccaf79a24b00c274bdaa'),\n",
       " ('+1', 'acb72b94764e480255cf52e9a0ba66c6fe536272'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('where', '46148cc3b4d2b3ac8073f14b0cba7f25ffff54bd'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('affiliated', 'cd481facc4a67daee3b52d12ebc21ca97d7d51c3'),\n",
       " ('with', '8fcd25a39d2037183044a8897e9a5333d727fded'),\n",
       " ('source', '828d338a9b04221c9cbe286f50cd389f68de4ecf'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('s', 'a0f1490a20d0211c997b44bc357e1972deab8ae3'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Affiliation', 'df55b450be2abe55e956289d6009082141509610'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('derived', '737aaa997690a6bbe5c9682ba6ac1911746a7b16'),\n",
       " ('from', '0b1e95cfd9775191a7224d0a218ae79187e80c1d'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('alignments', 'fb1a5c1c7487cd993b4929316313ab9c483a04a2'),\n",
       " ('using', '92bd75ebd8fd2b0179172217b15350cc6d4002f0'),\n",
       " ('heuristics', 'a628d3bfd9a306328c089830b667f91c5120b5da'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('To', 'ae79ea1e9c6391a9ed83a2e18a031b835feec0c9'),\n",
       " ('estimate', 'cb3fca157fd00bf7cbdee2410c6b27ca5e2e0752'),\n",
       " ('these', '81b781d39d62e9d0e272e181ce7802af3f0f94f7'),\n",
       " ('probabilities', '9d5fa0825055a7fad184227e60ccdc62238f31fd'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('uses', 'a7e2c648dc9941f38aea4196f90df226d6e93b2b'),\n",
       " ('m', '6b0d31c0d563223024da45691584643ac78c96e8'),\n",
       " ('source', '828d338a9b04221c9cbe286f50cd389f68de4ecf'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('n', 'd1854cae891ec7b29161ccaf79a24b00c274bdaa'),\n",
       " ('−', '6a4e6e729f96b07652599ea183dcceac72cdf70f'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('history', '66f79d8a6327c82c9033e6d65ff03322a3766c87'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('input', '140f86aae51ab9e1cda9b4254fe98a74eb54c1a1'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('neural', 'f2026117220d5bdf9c8ca78e6f2ceab7743990b5'),\n",
       " ('network', 'c112e88173d4d3c5c1409a17bee4837673523991'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('performs', '0601230d5a588dca2ef7dc18f75bd8ed1275bfcb'),\n",
       " ('estimation', '6fae58757e16134562ad327309dc715500e0ca48'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('unnormalized', '7a14cdb4b9586d4ab19334bb986125e44aad96c1'),\n",
       " ('probabilities', '9d5fa0825055a7fad184227e60ccdc62238f31fd'),\n",
       " ('p', '516b9783fca517eecbd1d064da2d165310b19759'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('before', '51de2b835bd35a67eb32dbcd3d77d4b96e5aa39d'),\n",
       " ('normalizing', '496d839c9efa6b10035d8ea2344db5fa2b216281'),\n",
       " ('over', 'f0fed7e4932302916b4e9c73fe47edcafeed7c44'),\n",
       " ('all', 'd87c448044defb778f33158d8ccf94a20531d600'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('vocabulary', '21861253d6fcd033c2f88da079e5750db84da93e'),\n",
       " ('V', 'c9ee5681d3c59f7541c27a38b67edf46259e187b'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('P', '511993d3c99719e38a6779073019dacd7178ddb9'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('p', '516b9783fca517eecbd1d064da2d165310b19759'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('Z', '909f99a779adb66a76fc53ab56c7dd1caf35d0fd'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('Z', '909f99a779adb66a76fc53ab56c7dd1caf35d0fd'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('∈', '22786abe461ed5640e012ed99b4b123910c73acd'),\n",
       " ('V', 'c9ee5681d3c59f7541c27a38b67edf46259e187b'),\n",
       " ('p', '516b9783fca517eecbd1d064da2d165310b19759'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('2', 'da4b9237bacccdf19c0760cab7aec4a8359010b0'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('where', '46148cc3b4d2b3ac8073f14b0cba7f25ffff54bd'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " ('stands', '355c6915844ff98feb0c30a0a35d6d8bc8f4a48e'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('source', '828d338a9b04221c9cbe286f50cd389f68de4ecf'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('target', '0e8a3ad980ec179856012b7eecf4327e99cd44cd'),\n",
       " ('context', 'ec2727b3b71f07635f726026bef44352ec89e452'),\n",
       " ('words', 'efb893611e6f56f5ad0724816340a50a4eb0820b'),\n",
       " ('as', 'df211ccdd94a63e0bcb9e6ae427a249484a49d60'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('Equation', '295e0d358155206b0b236f629b9fc8fd7965f352'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('The', '93ef0dd827103681fcee453b78be2ff14e1a261d'),\n",
       " ('NNJM', '9618bc53a5931f0c6cb6125f0f8eb00fb274a624'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('trained', 'f7f599e6b44c44fa168819ac6c8b2c914583c62b'),\n",
       " ('on', 'db3d405b10675998c030223177d42e71b4e7a312'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('word', '3cbcd90adc4b192a87a625850b7f231caddf0eb3'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('aligned', '3bea4606b8381d936b8f862d721bc4422652b565'),\n",
       " ('parallel', '1a9252013891fed7df5ef1bbf56c675a5560e127'),\n",
       " ('corpus', '62892ff8a183f45ee191a696796927ae39b2a604'),\n",
       " ('using', '92bd75ebd8fd2b0179172217b15350cc6d4002f0'),\n",
       " ('standard', 'f410e0466ae4b065bfa4d9010ad6056864ed4e50'),\n",
       " ('MLE', '5271b723b719259d50134696d371b560e1683abf'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('but', '786e97b3ee9fc4b292d5852c2c5943153c4ce91a'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('cost', '885dc4a9b362094fb138a3d17c4933bf3e8b9d85'),\n",
       " ('of', 'de04fa0e29f9b35e24905d2e512bedc9bb6e09e4'),\n",
       " ('normalizing', '496d839c9efa6b10035d8ea2344db5fa2b216281'),\n",
       " ('over', 'f0fed7e4932302916b4e9c73fe47edcafeed7c44'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('entire', '747761a820ea0860b14fc6679787e58916623a88'),\n",
       " ('vocabulary', '21861253d6fcd033c2f88da079e5750db84da93e'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('calculate', 'a8f700e7c0a3e16c92f8b2318433514e241ba38a'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('denominator', 'daffbbff101f0da7cc5f5f50526be62a911f6f78'),\n",
       " ('in', 'af10ef20dd9060bbeead0afbc55381a66af442ef'),\n",
       " ('Equation', '295e0d358155206b0b236f629b9fc8fd7965f352'),\n",
       " ('2', 'da4b9237bacccdf19c0760cab7aec4a8359010b0'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('quite', '5898102702f118870028aae25a26f24e32303248'),\n",
       " ('large', '5296d5cced2aa1cf19afd9cf498d89f0d85481f2'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('Devlin', '6019c3112e8a4477fcea9a984a124e3fc2cce288'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('2014', '39e21432a7dcba489697b4ef779f4b0c6f08b89f'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (\"'s\", '003e8ecdac1b420ae7fd1fe995fbd5d61cb5ae0c'),\n",
       " ('self', '40380bc1d358a6f8665b37bbdc8c7ccc6c38a861'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('normalization', '55ba1d472f08876b44dea01ba35de467949b0230'),\n",
       " ('technique', 'b41c6aff6d5da9bbcdc32f75c3fbe2009cdd6ed8'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('avoid', 'dec0734503a971da2e214b9d275cc34142e483ff'),\n",
       " ('normalization', '55ba1d472f08876b44dea01ba35de467949b0230'),\n",
       " ('cost', '885dc4a9b362094fb138a3d17c4933bf3e8b9d85'),\n",
       " ('during', 'ffed391ca2a6c8bb0b20f95bace87ef78d0c9f59'),\n",
       " ('decoding', 'a54087722f66e2368393bda323a8221081256b47'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('but', '786e97b3ee9fc4b292d5852c2c5943153c4ce91a'),\n",
       " ('not', '557f255516719ea16f8f4a0aae1166054e2c9b43'),\n",
       " ('during', 'ffed391ca2a6c8bb0b20f95bace87ef78d0c9f59'),\n",
       " ('training', '0a2b9827e548969e4dfe1b0d16c072ef347836d6'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " ('can', '7e9219a0599eae1d9601883f894b4fbe60870586'),\n",
       " ('be', '986b1bc1eb8de89643c50722910f99001c232865'),\n",
       " ('used', '192a56759d36454cc0b8c812e31845e9ed10b130'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('train', '94efdd6f628eda9c1ae893467c9652808443ef3e'),\n",
       " ('NNLM', '19e70e4b37daad9e8664227a48457488a4ee19d5'),\n",
       " ('-', '3bc15c8aae3e4124dd409035f32ea2fd6835efc9'),\n",
       " ('style', '26ec8d00fb6b55466b3a115f1d559422a7fa7aac'),\n",
       " ('models', '5ba2688dffd71df813a468578a87c653e1575e1e'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('Vaswani', '521499abcabf9575e6d8bc9d443b1a7f2c0616e0'),\n",
       " ('et', 'a5bc1d9b2ae74e7a8a249659c13b14f5c2eac13f'),\n",
       " ('al.', 'dd6700c355e2b4693588d5900c92f052a627ba56'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('2013', 'd08b10a32612f9d3bc06be41124becfd39536eee'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('reduce', '48c3689f6dd5e9e952f925b7ebebf64d7c43fc56'),\n",
       " ('training', '0a2b9827e548969e4dfe1b0d16c072ef347836d6'),\n",
       " ('times', '7196b5875f713c826bd279dbda843c897e2a60c2'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " ('creates', '22f0a27d79bfa68c634156931dd1b20dff82ee4b'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('distribution', 'c6fbbcc823401b2122e8791c3e6ff154f83ff4ad'),\n",
       " ('q', '22ea1c649c82946aa6e479e1ffd321e4a318b1b0'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('selects', 'f7c4ad4341902e7301c8bf58d120bd8b88a85604'),\n",
       " ('k', '13fbd79c3d390e5d6585a21e11ff5ec1970cff0c'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('samples', '433cdfecfbc5711be2ee148baa19038de415879b'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i1', '3795b54c5ba62df52f7f5132a3c17a2191fc7f74'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('...', '6eae3a5b062c6d0d79f070c26e6d62486b40cb46'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('ik', '1ad31d0cc2072780d635a199141db834fc06d817'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('each', 'b32f279e548b6fceef4343170778273bfe60658c'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('introduces', 'fa32f507eb669f21a0129164602f664461ffef85'),\n",
       " ('a', '86f7e437faa5a7fce15d1ddcb9eaeaea377667b8'),\n",
       " ('random', 'a415ab5cc17c8c093c015ccdb7e552aee7911aa4'),\n",
       " ('variable', 'b46d0172433dd6895dac7544b9dacbb87b361e9f'),\n",
       " ('v', '7a38d8cbd20d9932ba948efaa364bb62651d5ad4'),\n",
       " ('which', 'ed04ff4dabf1e2d4cd6b89136c2b24dec27ecca4'),\n",
       " ('is', 'b47f363e2b430c0647f14deea3eced9b0ef300ce'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('training', '0a2b9827e548969e4dfe1b0d16c072ef347836d6'),\n",
       " ('examples', '99345ce680cd3e48acdb9ab4212e4bd9bf9358b7'),\n",
       " ('and', 'cffa50a32cb13a240d705317bcec65dd1f31b6ad'),\n",
       " ('0', 'b6589fc6ab0dc82cf12099d1c2d40ab994e8410c'),\n",
       " ('for', '43eef9a62abb8b1e1654f8a890aae054abffa82b'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('samples', '433cdfecfbc5711be2ee148baa19038de415879b'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('P', '511993d3c99719e38a6779073019dacd7178ddb9'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('v', '7a38d8cbd20d9932ba948efaa364bb62651d5ad4'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('+', 'a979ef10cc6f6a36df6b8a323307ee3bb2e2db9c'),\n",
       " ('k', '13fbd79c3d390e5d6585a21e11ff5ec1970cff0c'),\n",
       " ('·', '1fdf0d90c37af3a1dbd95c068144b1895c063a5e'),\n",
       " ('p', '516b9783fca517eecbd1d064da2d165310b19759'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('Z', '909f99a779adb66a76fc53ab56c7dd1caf35d0fd'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('P', '511993d3c99719e38a6779073019dacd7178ddb9'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('v', '7a38d8cbd20d9932ba948efaa364bb62651d5ad4'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('0', 'b6589fc6ab0dc82cf12099d1c2d40ab994e8410c'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('k', '13fbd79c3d390e5d6585a21e11ff5ec1970cff0c'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('+', 'a979ef10cc6f6a36df6b8a323307ee3bb2e2db9c'),\n",
       " ('k', '13fbd79c3d390e5d6585a21e11ff5ec1970cff0c'),\n",
       " ('·', '1fdf0d90c37af3a1dbd95c068144b1895c063a5e'),\n",
       " ('q', '22ea1c649c82946aa6e479e1ffd321e4a318b1b0'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('t', '8efd86fb78a56a5145ed7739dcb00c78581c5375'),\n",
       " ('i', '042dc4512fa3d391c5170cf3aa61e6a638f84342'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('.', '3a52ce780950d4d969792a2559cd519d7ee8c727'),\n",
       " ('NCE', '8846efbad185a96d0afad99e61b6b14fa2f75055'),\n",
       " ('trains', 'd9e7dc7f09854cc2453134c5b961726e6a12aa76'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('model', '1d06a0d76f000e6edd18de492383983feefced4e'),\n",
       " ('to', '4374aaee247fb237ce6c97d5c8d64bbe474d16de'),\n",
       " ('distinguish', 'a66bc3d8c18aabe1f01d8f604a6270d46de2cdd5'),\n",
       " ('training', '0a2b9827e548969e4dfe1b0d16c072ef347836d6'),\n",
       " ('data', 'a17c9aaa61e80a1bf71d0d850af4e5baa9800bbd'),\n",
       " ('from', '0b1e95cfd9775191a7224d0a218ae79187e80c1d'),\n",
       " ('noise', '9424ac79de34c97c74261622b533d185ca13968a'),\n",
       " ('by', '408158643ed564c72fa0921826f8294d71ccbf7c'),\n",
       " ('maximize', 'faab8bc6f1329a61437617193c479f328e2f50a9'),\n",
       " ('the', 'bbccdf2efb33b52e6c9d0a14dd70b2d415fbea6e'),\n",
       " ('conditional', '8db74851106a36fd1bb6bca2a63409a5e13bcd5b'),\n",
       " ('likelihood', 'b4f899713e792e9cbb273d345f93d9f3123fa141'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('L', 'd160e0986aca4714714a16f29ec605af90be704d'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('log', '7babc233de26ab19ead1b9c278128d5c434910ee'),\n",
       " ('P', '511993d3c99719e38a6779073019dacd7178ddb9'),\n",
       " ('(', '28ed3a797da3c48c309a4ef792147f3c56cfec40'),\n",
       " ('v', '7a38d8cbd20d9932ba948efaa364bb62651d5ad4'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('|', '3eb416223e9e69e6bb8ee19793911ad1ad2027d8'),\n",
       " ('C', '32096c2e0eff33d844ee6d675407ace18289357d'),\n",
       " (',', '5c10b5b2cd673a0616d529aa5234b12ee7153808'),\n",
       " ('ti', '41c76e5218177bb90eb3d29d24da7b418a07d440'),\n",
       " (')', 'e7064f0b80f61dbc65915311032d27baa569ae2a'),\n",
       " ('+', 'a979ef10cc6f6a36df6b8a323307ee3bb2e2db9c'),\n",
       " ('k', '13fbd79c3d390e5d6585a21e11ff5ec1970cff0c'),\n",
       " ('j', '5c2dd944dde9e08881bef0894fe7b22a5c9c4b06'),\n",
       " ('=', '21606782c65e44cac7afbb90977d8b6f82140e76'),\n",
       " ('1', '356a192b7913b04c54574d18c28d46e6395428ab'),\n",
       " ('log', '7babc233de26ab19ead1b9c278128d5c434910ee'),\n",
       " ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(zip(lines, toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['./tok.sh', '/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for root, dirs, files in os.walk('/home/devansh/Documents/EMNLP/Parsers/OUT_1/'):\n",
    "        for file in files:\n",
    "            inp = '/home/devansh/Documents/EMNLP/Parsers/OUT_1/' + str(file) + '/' + str(file)\n",
    "            print(inp)\n",
    "            subprocess.call(['./tok.sh', inp])\n",
    "            lines = open('out.txt').read().splitlines()\n",
    "            toks = list(map(lambda x: hashhex(x), lines))\n",
    "            outp = '/home/devansh/Documents/EMNLP/Parsers/OUT_1/' + str(file) + '/' + 'tokenized'\n",
    "            with open(outp, \"w\") as outfile:\n",
    "                outfile.write(\"\\n\".join(toks))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Using_Out-of-Domain_Data_for_Lexical_Addressee_Detection_in_Human-Human-Computer_Dialog/Using_Out-of-Domain_Data_for_Lexical_Addressee_Detection_in_Human-Human-Computer_Dialog\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Canonical_Tensor_Decomposition_for_Knowledge_Base_Completion/Canonical_Tensor_Decomposition_for_Knowledge_Base_Completion\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Probabilistic_Logic__A_Unifying_Framework_for_Indirect_Supervision/Deep_Probabilistic_Logic__A_Unifying_Framework_for_Indirect_Supervision\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Enriching_Word_Vectors_with_Subword_Information/Enriching_Word_Vectors_with_Subword_Information\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adaptive_Exploration-Exploitation_Tradeoff_for_Opportunistic_Bandits/Adaptive_Exploration-Exploitation_Tradeoff_for_Opportunistic_Bandits\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Retrieval_of_the_Best_Counterargument_without_Prior_Topic_Knowledge/Retrieval_of_the_Best_Counterargument_without_Prior_Topic_Knowledge\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Semismooth_Newton_Method_for_Fast,_Generic_Convex_Programming/A_Semismooth_Newton_Method_for_Fast,_Generic_Convex_Programming\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Extending_a_Parser_to_Distant_Domains_Using_a_Few_Dozen_Partially_Annotated_Examples/Extending_a_Parser_to_Distant_Domains_Using_a_Few_Dozen_Partially_Annotated_Examples\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Variational_Bayesian_dropout__pitfalls_and_fixes/Variational_Bayesian_dropout__pitfalls_and_fixes\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Open_Domain_Question_Answering_Using_Early_Fusion_of_Knowledge_Bases_and_Text/Open_Domain_Question_Answering_Using_Early_Fusion_of_Knowledge_Bases_and_Text\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Parallel_Multiscale_Autoregressive_Density_Estimation/Parallel_Multiscale_Autoregressive_Density_Estimation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multimodal_Language_Analysis_with_Recurrent_Multistage_Fusion/Multimodal_Language_Analysis_with_Recurrent_Multistage_Fusion\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Why_is_unsupervised_alignment_of_English_embeddings_from_different_algorithms_so_hard_/Why_is_unsupervised_alignment_of_English_embeddings_from_different_algorithms_so_hard_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Document_Modeling_with_External_Attention_for_Sentence_Extraction/Document_Modeling_with_External_Attention_for_Sentence_Extraction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Numeracy_for_Language_Models__Evaluating_and_Improving_their_Ability_to_Predict_Numbers/Numeracy_for_Language_Models__Evaluating_and_Improving_their_Ability_to_Predict_Numbers\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Did_the_Model_Understand_the_Question_/Did_the_Model_Understand_the_Question_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Role_play-based_question-answering_by_real_users_for_building_chatbots_with_consistent_personalities/Role_play-based_question-answering_by_real_users_for_building_chatbots_with_consistent_personalities\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Unsupervised_Neural_Attention_Model_for_Aspect_Extraction/An_Unsupervised_Neural_Attention_Model_for_Aspect_Extraction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Demand-Weighted_Completeness_Prediction_for_a_Knowledge_Base/Demand-Weighted_Completeness_Prediction_for_a_Knowledge_Base\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Networks_for_Open_Domain_Targeted_Sentiment/Neural_Networks_for_Open_Domain_Targeted_Sentiment\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Using_Personal_Traits_For_Brand_Preference_Prediction/Using_Personal_Traits_For_Brand_Preference_Prediction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Capacity_Releasing_Diffusion_for_Speed_and_Locality/Capacity_Releasing_Diffusion_for_Speed_and_Locality\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Modular_Multitask_Reinforcement_Learning_with_Policy_Sketches/Modular_Multitask_Reinforcement_Learning_with_Policy_Sketches\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Variance-Reduced_Hamilton_Monte_Carlo_Methods/Stochastic_Variance-Reduced_Hamilton_Monte_Carlo_Methods\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Polyglot_Semantic_Role_Labeling/Polyglot_Semantic_Role_Labeling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Forest-type_Regression_with_General_Losses__and_Robust_Forest/Forest-type_Regression_with_General_Losses__and_Robust_Forest\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Hierarchical_Recurrent_Neural_Network_for_Document_Modeling/Hierarchical_Recurrent_Neural_Network_for_Document_Modeling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Evaluating_the_Variance_of_Likelihood-Ratio_Gradient_Estimators/Evaluating_the_Variance_of_Likelihood-Ratio_Gradient_Estimators\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Study_of_Reinforcement_Learning_for_Neural_Machine_Translation/A_Study_of_Reinforcement_Learning_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Spline_Theory_of_Deep_Networks/A_Spline_Theory_of_Deep_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Doubly_Accelerated_Methods_for_Faster_CCA__and_Generalized_Eigendecomposition/Doubly_Accelerated_Methods_for_Faster_CCA__and_Generalized_Eigendecomposition\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Pieces_of_Eight__8-bit_Neural_Machine_Translation/Pieces_of_Eight__8-bit_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Detecting_Risks_in_the_Banking_System_by_Sentiment_Analysis/Detecting_Risks_in_the_Banking_System_by_Sentiment_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Modelling_Protagonist_Goals_and_Desires_in_First-Person_Narrative/Modelling_Protagonist_Goals_and_Desires_in_First-Person_Narrative\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Knowledge_transfer_between_speakers_for_personalised_dialogue_management/Knowledge_transfer_between_speakers_for_personalised_dialogue_management\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Active_Learning_for_Cost-Sensitive_Classification/Active_Learning_for_Cost-Sensitive_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Know-Evolve__Deep_Temporal_Reasoning_for_Dynamic_Knowledge_Graphs/Know-Evolve__Deep_Temporal_Reasoning_for_Dynamic_Knowledge_Graphs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Convolutional_Sequence_to_Sequence_Learning/Convolutional_Sequence_to_Sequence_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Socially-Informed_Timeline_Generation_for_Complex_Events/Socially-Informed_Timeline_Generation_for_Complex_Events\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Has_Machine_Translation_Achieved_Human_Parity__A_Case_for_Document-level_Evaluation/Has_Machine_Translation_Achieved_Human_Parity__A_Case_for_Document-level_Evaluation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Call_Centre_Conversation_Summarization__A_Pilot_Task_at_Multiling_2015/Call_Centre_Conversation_Summarization__A_Pilot_Task_at_Multiling_2015\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarial_Connective-exploiting_Networks_for_Implicit_Discourse_Relation_Classification/Adversarial_Connective-exploiting_Networks_for_Implicit_Discourse_Relation_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_beyond_datasets__Knowledge_Graph_Augmented_Neural_Networks_for_Natural_language_Processing/Learning_beyond_datasets__Knowledge_Graph_Augmented_Neural_Networks_for_Natural_language_Processing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Dirichlet_Multinomial_Regression/Deep_Dirichlet_Multinomial_Regression\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Structured_Multi-Label_Biomedical_Text_Tagging_via_Attentive_Neural_Tree_Decoding/Structured_Multi-Label_Biomedical_Text_Tagging_via_Attentive_Neural_Tree_Decoding\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Joint_Semantic_Parsers_from_Disjoint_Data/Learning_Joint_Semantic_Parsers_from_Disjoint_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/When_can_Multi-Site_Datasets_be_Pooled_for_Regression__Hypothesis_Tests,_2-consistency_and_Neuroscience_Applications/When_can_Multi-Site_Datasets_be_Pooled_for_Regression__Hypothesis_Tests,_2-consistency_and_Neuroscience_Applications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Multilinear_Structure_of_ReLU_Networks/The_Multilinear_Structure_of_ReLU_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_One_Convolutional_Layer_with_Overlapping_Patches/Learning_One_Convolutional_Layer_with_Overlapping_Patches\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deciding_How_to_Decide___Dynamic_Routing_in_Artificial_Neural_Networks/Deciding_How_to_Decide___Dynamic_Routing_in_Artificial_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Crowdsourcing_with_Arbitrary_Adversaries/Crowdsourcing_with_Arbitrary_Adversaries\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Tree-based_Decoder_for_Neural_Machine_Translation/A_Tree-based_Decoder_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multi-Fidelity_Black-Box_Optimization_with_Hierarchical_Partitions/Multi-Fidelity_Black-Box_Optimization_with_Hierarchical_Partitions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Hyperplane_Clustering_via_Dual_Principal_Component_Pursuit/Hyperplane_Clustering_via_Dual_Principal_Component_Pursuit\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_data-driven_model_of_explanations_for_a_chatbot_that_helps_to_practice_conversation_in_a_foreign_language/A_data-driven_model_of_explanations_for_a_chatbot_that_helps_to_practice_conversation_in_a_foreign_language\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Robust_Gaussian_Graphical_Model_Estimation_with_Arbitrary_Corruption/Robust_Gaussian_Graphical_Model_Estimation_with_Arbitrary_Corruption\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Convex_Optimization__Faster_Local_Growth_Implies_Faster_Global_Convergence/Stochastic_Convex_Optimization__Faster_Local_Growth_Implies_Faster_Global_Convergence\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Framework_for_Understanding_the_Role_of_Morphology_in_Universal_Dependency_Parsing/A_Framework_for_Understanding_the_Role_of_Morphology_in_Universal_Dependency_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Topic_Models_with_Latent_Feature_Word_Representations/Improving_Topic_Models_with_Latent_Feature_Word_Representations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Gromov-Wasserstein_Alignment_of_Word_Embedding_Spaces/Gromov-Wasserstein_Alignment_of_Word_Embedding_Spaces\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Infinite_Hidden_Markov_Model_With_Similarity-Biased_Transitions/An_Infinite_Hidden_Markov_Model_With_Similarity-Biased_Transitions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unsupervised_Induction_of_Semantic_Roles_within_a_Reconstruction-Error_Minimization_Framework/Unsupervised_Induction_of_Semantic_Roles_within_a_Reconstruction-Error_Minimization_Framework\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/CALCS__Continuously_Approximating_Longest_Common_Subsequence_for_Sequence_Level_Optimization/CALCS__Continuously_Approximating_Longest_Common_Subsequence_for_Sequence_Level_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reasoning_with_Heterogeneous_Knowledge_for_Commonsense_Machine_Comprehension/Reasoning_with_Heterogeneous_Knowledge_for_Commonsense_Machine_Comprehension\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Statistical_Inference_for_Incomplete_Ranking_Data__The_Case_of_Rank-Dependent_Coarsening/Statistical_Inference_for_Incomplete_Ranking_Data__The_Case_of_Rank-Dependent_Coarsening\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Signal_and_Noise_Statistics_Oblivious_Orthogonal_Matching_Pursuit_/Signal_and_Noise_Statistics_Oblivious_Orthogonal_Matching_Pursuit_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Coarse-to-Fine_Decoding_for_Neural_Semantic_Parsing/Coarse-to-Fine_Decoding_for_Neural_Semantic_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/On_Calibration_of_Modern_Neural_Networks/On_Calibration_of_Modern_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Quickshift++__Provably_Good_Initializations_for_Sample-Based_Mean_Shift/Quickshift++__Provably_Good_Initializations_for_Sample-Based_Mean_Shift\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Native_Language_Cognate_Effects_on_Second_Language_Lexical_Choice/Native_Language_Cognate_Effects_on_Second_Language_Lexical_Choice\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Uncertainty_Assessment_and_False_Discovery_Rate_Control_in_High-Dimensional_Granger_Causal_Inference/Uncertainty_Assessment_and_False_Discovery_Rate_Control_in_High-Dimensional_Granger_Causal_Inference\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Inducing_Temporal_Relations_from_Time_Anchor_Annotation/Inducing_Temporal_Relations_from_Time_Anchor_Annotation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/NEXUS_Network__Connecting_the_Preceding_and_the_Following_in_Dialogue_Generation/NEXUS_Network__Connecting_the_Preceding_and_the_Following_in_Dialogue_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Efficient_Orthogonal_Parametrisation_of_Recurrent_Neural_Networks__Using_Householder_Reflections/Efficient_Orthogonal_Parametrisation_of_Recurrent_Neural_Networks__Using_Householder_Reflections\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Firing_Bandits__Optimizing_Crowdfunding/Firing_Bandits__Optimizing_Crowdfunding\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Intra-Sentential_Subject_Zero_Anaphora_Resolution_using_Multi-Column_Convolutional_Neural_Network/Intra-Sentential_Subject_Zero_Anaphora_Resolution_using_Multi-Column_Convolutional_Neural_Network\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Theoretical_Explanation_for_Perplexing_Behaviors_of_Backpropagation-based_Visualizations/A_Theoretical_Explanation_for_Perplexing_Behaviors_of_Backpropagation-based_Visualizations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Implicit_Regularization_in_Nonconvex_Statistical_Estimation__Gradient_Descent_Converges_Linearly_for_Phase_Retrieval_and_Matrix_Completion/Implicit_Regularization_in_Nonconvex_Statistical_Estimation__Gradient_Descent_Converges_Linearly_for_Phase_Retrieval_and_Matrix_Completion\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bridging_Languages_through_Images_with_Deep_Partial_Canonical_Correlation_Analysis/Bridging_Languages_through_Images_with_Deep_Partial_Canonical_Correlation_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sparse_Coding_of_Neural_Word_Embeddings_for_Multilingual_Sequence_Labeling(1)/Sparse_Coding_of_Neural_Word_Embeddings_for_Multilingual_Sequence_Labeling(1)\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Predicting_Native_Language_from_Gaze/Predicting_Native_Language_from_Gaze\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Sentiment-Specific_Word_Embedding_for_Twitter_Sentiment_Classification/Learning_Sentiment-Specific_Word_Embedding_for_Twitter_Sentiment_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Argument_Reasoning_Comprehension_Task__Identification_and_Reconstruction_of_Implicit_Warrants/The_Argument_Reasoning_Comprehension_Task__Identification_and_Reconstruction_of_Implicit_Warrants\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Gram-CTC__Automatic_Unit_Selection_and_Target_Decomposition_for_Sequence_Labelling/Gram-CTC__Automatic_Unit_Selection_and_Target_Decomposition_for_Sequence_Labelling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Convolutional_Neural_Network_Language_Models/Convolutional_Neural_Network_Language_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Subgoal_Discovery_for_Hierarchical_Dialogue_Policy_Learning/Subgoal_Discovery_for_Hierarchical_Dialogue_Policy_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reducing_Gender_Bias_in_Abusive_Language_Detection/Reducing_Gender_Bias_in_Abusive_Language_Detection\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Semi-Supervised_Discriminative_Language_Modeling_with_Out-of-Domain_Text_Data/Semi-Supervised_Discriminative_Language_Modeling_with_Out-of-Domain_Text_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Characterizing_Interactions_and_Relationships_between_People/Characterizing_Interactions_and_Relationships_between_People\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Where_is_Misty__Interpreting_Spatial_Descriptors_by_Modeling_Regions_in_Space/Where_is_Misty__Interpreting_Spatial_Descriptors_by_Modeling_Regions_in_Space\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adaptive_Consensus_ADMM_for_Distributed_Optimization/Adaptive_Consensus_ADMM_for_Distributed_Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Decentralized_Submodular_Maximization__Bridging_Discrete_and_Continuous_Settings/Decentralized_Submodular_Maximization__Bridging_Discrete_and_Continuous_Settings\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Label-aware_Double_Transfer_Learning_for_Cross-Specialty_Medical_Named_Entity_Recognition/Label-aware_Double_Transfer_Learning_for_Cross-Specialty_Medical_Named_Entity_Recognition\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adaptive_Knowledge_Sharing_in_Multi-Task_Learning__Improving_Low-Resource_Neural_Machine_Translation/Adaptive_Knowledge_Sharing_in_Multi-Task_Learning__Improving_Low-Resource_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Trainable_Greedy_Decoding_for_Neural_Machine_Translation/Trainable_Greedy_Decoding_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Consistent_k-Clustering/Consistent_k-Clustering\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_to_Align_the_Source_Code_to_the_Compiled_Object_Code/Learning_to_Align_the_Source_Code_to_the_Compiled_Object_Code\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Context-dependent_Semantic_Parsing_for_Time_Expressions/Context-dependent_Semantic_Parsing_for_Time_Expressions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Segmentation_for_Efficient_Supervised_Language_Annotation_with_an_Explicit_Cost-Utility_Tradeoff/Segmentation_for_Efficient_Supervised_Language_Annotation_with_an_Explicit_Cost-Utility_Tradeoff\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Head-Lexicalized_Bidirectional_Tree_LSTMs/Head-Lexicalized_Bidirectional_Tree_LSTMs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Structured_Learning_Approach_to_Temporal_Relation_Extraction/A_Structured_Learning_Approach_to_Temporal_Relation_Extraction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Convolutional_Encoder_Model_for_Neural_Machine_Translation/A_Convolutional_Encoder_Model_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Evaluating_Compound_Splitters_Extrinsically_with_Textual_Entailment/Evaluating_Compound_Splitters_Extrinsically_with_Textual_Entailment\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unsupervised_Counselor_Dialogue_Clustering_for_Positive_Emotion_Elicitation_in_Neural_Dialogue_System/Unsupervised_Counselor_Dialogue_Clustering_for_Positive_Emotion_Elicitation_in_Neural_Dialogue_System\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Relations_such_as_Hypernymy__Identifying_and_Exploiting_Hearst_Patterns_in_Distributional_Vectors_for_Lexical_Entailment/Relations_such_as_Hypernymy__Identifying_and_Exploiting_Hearst_Patterns_in_Distributional_Vectors_for_Lexical_Entailment\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bandits_with_Delayed,_Aggregated_Anonymous_Feedback/Bandits_with_Delayed,_Aggregated_Anonymous_Feedback\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Faster_Principal_Component_Regression__and_Stable_Matrix_Chebyshev_Approximation/Faster_Principal_Component_Regression__and_Stable_Matrix_Chebyshev_Approximation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Robust_Submodular_Maximization___A_Non-Uniform_Partitioning_Approach/Robust_Submodular_Maximization___A_Non-Uniform_Partitioning_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Multi-sentiment-resource_Enhanced_Attention_Network_for_Sentiment_Classification/A_Multi-sentiment-resource_Enhanced_Attention_Network_for_Sentiment_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Towards_an_Automatic_Turing_Test__Learning_to_Evaluate_Dialogue_Responses/Towards_an_Automatic_Turing_Test__Learning_to_Evaluate_Dialogue_Responses\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/WIKIQA__A_Challenge_Dataset_for_Open-Domain_Question_Answering/WIKIQA__A_Challenge_Dataset_for_Open-Domain_Question_Answering\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/DeepPath__A_Reinforcement_Learning_Method_for_Knowledge_Graph_Reasoning/DeepPath__A_Reinforcement_Learning_Method_for_Knowledge_Graph_Reasoning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Estimation_and_Analysis_Framework_for_the_Rasch_Model/An_Estimation_and_Analysis_Framework_for_the_Rasch_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Toward_incremental_dialogue_act_segmentation_in_fast-paced_interactive_dialogue_systems/Toward_incremental_dialogue_act_segmentation_in_fast-paced_interactive_dialogue_systems\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Hierarchical_Neural_Networks_for_Sequential_Sentence_Classification_in_Medical_Scientific_Abstracts/Hierarchical_Neural_Networks_for_Sequential_Sentence_Classification_in_Medical_Scientific_Abstracts\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Reinforcement_Learning_for_Dialogue_Generation/Deep_Reinforcement_Learning_for_Dialogue_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Scalable_Generative_Models_for_Multi-label_Learning_with_Missing_Labels/Scalable_Generative_Models_for_Multi-label_Learning_with_Missing_Labels\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deterministic_Non-Autoregressive_Neural_Sequence_Modeling_by_Iterative_Refinement/Deterministic_Non-Autoregressive_Neural_Sequence_Modeling_by_Iterative_Refinement\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Automatic_Extraction_of_Implicit_Interpretations_from_Modal_Constructions/Automatic_Extraction_of_Implicit_Interpretations_from_Modal_Constructions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Temporally_Grounding_Natural_Sentence_in_Video/Temporally_Grounding_Natural_Sentence_in_Video\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Distant_Supervision_for_Relation_Extraction_via_Piecewise_Convolutional_Neural_Networks/Distant_Supervision_for_Relation_Extraction_via_Piecewise_Convolutional_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Gaussian_Mixture_Latent_Vector_Grammars/Gaussian_Mixture_Latent_Vector_Grammars\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Efficient,_Sparsity-Preserving,_Online_Algorithm_for_Low-Rank_Approximation/An_Efficient,_Sparsity-Preserving,_Online_Algorithm_for_Low-Rank_Approximation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Identifying_Domain_Independent_Update_Intents_in_Task_Based_Dialogs/Identifying_Domain_Independent_Update_Intents_in_Task_Based_Dialogs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Beyond_Filters__Compact_Feature_Map_for_Portable_Deep_Model/Beyond_Filters__Compact_Feature_Map_for_Portable_Deep_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Maximum_Selection_and_Ranking_under_Noisy_Comparisons/Maximum_Selection_and_Ranking_under_Noisy_Comparisons\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Evaluating_Theory_of_Mind_in_Question_Answering(1)/Evaluating_Theory_of_Mind_in_Question_Answering(1)\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Predicate_Argument_Alignment_using_a_Global_Coherence_Model/Predicate_Argument_Alignment_using_a_Global_Coherence_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Two-Stage_Parsing_Method_for_Text-Level_Discourse_Analysis/A_Two-Stage_Parsing_Method_for_Text-Level_Discourse_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Segmental_Hypergraphs_for_Overlapping_Mention_Recognition/Neural_Segmental_Hypergraphs_for_Overlapping_Mention_Recognition\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Axiomatic_Attribution_for_Deep_Networks/Axiomatic_Attribution_for_Deep_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Principled_Framework_for_Evaluating_Summarizers__Comparing_Models_of_Summary_Quality_against_Human_Judgments/A_Principled_Framework_for_Evaluating_Summarizers__Comparing_Models_of_Summary_Quality_against_Human_Judgments\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/XNLI__Evaluating_Cross-lingual_Sentence_Representations/XNLI__Evaluating_Cross-lingual_Sentence_Representations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Cross-topic_Argument_Mining_from_Heterogeneous_Sources/Cross-topic_Argument_Mining_from_Heterogeneous_Sources\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Speech_segmentation_with_a_neural_encoder_model_of_working_memory/Speech_segmentation_with_a_neural_encoder_model_of_working_memory\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Differentiable_Compositional_Kernel_Learning_for_Gaussian_Processes/Differentiable_Compositional_Kernel_Learning_for_Gaussian_Processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Compact,_Efficient_and_Unlimited_Capacity__Language_Modeling_with_Compressed_Suffix_Trees/Compact,_Efficient_and_Unlimited_Capacity__Language_Modeling_with_Compressed_Suffix_Trees\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Inductive_Two-layer_Modeling_with_Parametric_Bregman_Transfer/Inductive_Two-layer_Modeling_with_Parametric_Bregman_Transfer\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Modeling_Naive_Psychology_of_Characters_in_Simple_Commonsense_Stories/Modeling_Naive_Psychology_of_Characters_in_Simple_Commonsense_Stories\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Supervised_Attentions_for_Neural_Machine_Translation/Supervised_Attentions_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Just_Sort_It!_A_Simple_and_Effective_Approach_to_Active_Preference_Learning/Just_Sort_It!_A_Simple_and_Effective_Approach_to_Active_Preference_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Understanding_Negation_in_Positive_Terms_Using_Syntactic_Dependencies/Understanding_Negation_in_Positive_Terms_Using_Syntactic_Dependencies\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Episodic_Control/Neural_Episodic_Control\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/End-to-End_Differentiable_Adversarial_Imitation_Learning/End-to-End_Differentiable_Adversarial_Imitation_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/How_to_Memorize_a_Random_60-Bit_String/How_to_Memorize_a_Random_60-Bit_String\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Regret_Minimization_in_Behaviorally-Constrained_Zero-Sum_Games/Regret_Minimization_in_Behaviorally-Constrained_Zero-Sum_Games\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Supersense_Tagging_for_Arabic__the_MT-in-the-Middle_Attack/Supersense_Tagging_for_Arabic__the_MT-in-the-Middle_Attack\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multi-Class_Optimal_Margin_Distribution_Machine/Multi-Class_Optimal_Margin_Distribution_Machine\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Specialising_Word_Vectors_for_Lexical_Entailment/Specialising_Word_Vectors_for_Lexical_Entailment\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bootstrapping_Generators_from_Noisy_Data/Bootstrapping_Generators_from_Noisy_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Token-level_and_sequence-level_loss_smoothing_for_RNN_language_models/Token-level_and_sequence-level_loss_smoothing_for_RNN_language_models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Hierarchical_Structured_Model_for_Fine-to-coarse_Manifesto_Text_Analysis/Hierarchical_Structured_Model_for_Fine-to-coarse_Manifesto_Text_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Structured_Variationally_Auto-encoded_Optimization/Structured_Variationally_Auto-encoded_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Syntax_for_Semantic_Role_Labeling,_To_Be,_Or_Not_To_Be/Syntax_for_Semantic_Role_Labeling,_To_Be,_Or_Not_To_Be\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/DCFNet__Deep_Neural_Network_with_Decomposed_Convolutional_Filters/DCFNet__Deep_Neural_Network_with_Decomposed_Convolutional_Filters\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Marrying_Up_Regular_Expressions_with_Neural_Networks__A_Case_Study_for_Spoken_Language_Understanding/Marrying_Up_Regular_Expressions_with_Neural_Networks__A_Case_Study_for_Spoken_Language_Understanding\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Theoretical_Analysis_of_Sparse_Subspace_Clustering_with_Missing_Entries/Theoretical_Analysis_of_Sparse_Subspace_Clustering_with_Missing_Entries\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Relative_Fisher_Information_and_Natural_Gradient_for_Learning_Large_Modular_Models/Relative_Fisher_Information_and_Natural_Gradient_for_Learning_Large_Modular_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Extracting_Condition-Opinion_Relations_Toward_Fine-grained_Opinion_Mining/Extracting_Condition-Opinion_Relations_Toward_Fine-grained_Opinion_Mining\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Re-revisiting_Learning_on_Hypergraphs___Confidence_Interval_and_Subgradient_Method/Re-revisiting_Learning_on_Hypergraphs___Confidence_Interval_and_Subgradient_Method\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Why_Swear__Analyzing_and_Inferring_the_Intentions_of_Vulgar_Expressions/Why_Swear__Analyzing_and_Inferring_the_Intentions_of_Vulgar_Expressions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Tied_Multitask_Learning_for_Neural_Speech_Translation/Tied_Multitask_Learning_for_Neural_Speech_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sentence_Compression_for_Arbitrary_Languages_via_Multilingual_Pivoting/Sentence_Compression_for_Arbitrary_Languages_via_Multilingual_Pivoting\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Parsing_Speech__A_Neural_Approach_to_Integrating_Lexical_and_Acoustic-Prosodic_Information/Parsing_Speech__A_Neural_Approach_to_Integrating_Lexical_and_Acoustic-Prosodic_Information\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Testing_Sparsity_over_Known_and_Unknown_Bases/Testing_Sparsity_over_Known_and_Unknown_Bases\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Soft_Actor-Critic__Off-Policy_Maximum_Entropy_Deep_Reinforcement_Learning_with_a_Stochastic_Actor/Soft_Actor-Critic__Off-Policy_Maximum_Entropy_Deep_Reinforcement_Learning_with_a_Stochastic_Actor\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_unknown_ODE_models_with_Gaussian_processes/Learning_unknown_ODE_models_with_Gaussian_processes\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unimodal_Probability_Distributions_for_Deep_Ordinal_Classification/Unimodal_Probability_Distributions_for_Deep_Ordinal_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Statistical_Recurrent_Unit/The_Statistical_Recurrent_Unit\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/MISSION__Ultra_Large-Scale_Feature_Selection_using_Count-Sketches/MISSION__Ultra_Large-Scale_Feature_Selection_using_Count-Sketches\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Heterogeneous_Supervision_for_Relation_Extraction__A_Representation_Learning_Approach/Heterogeneous_Supervision_for_Relation_Extraction__A_Representation_Learning_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarial_Training_for_Multi-task_and_Multi-lingual_Joint_Modeling_of_Utterance_Intent_Classification/Adversarial_Training_for_Multi-task_and_Multi-lingual_Joint_Modeling_of_Utterance_Intent_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reasoning_with_Sarcasm_by_Reading_In-between/Reasoning_with_Sarcasm_by_Reading_In-between\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/meProp__Sparsified_Back_Propagation_for_Accelerated_Deep_Learning_with_Reduced_Overfitting/meProp__Sparsified_Back_Propagation_for_Accelerated_Deep_Learning_with_Reduced_Overfitting\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Fine-Grained_Entity_Type_Classification_with_Hierarchy-Aware_Loss/Neural_Fine-Grained_Entity_Type_Classification_with_Hierarchy-Aware_Loss\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Breaking_Locality_Accelerates_Block_Gauss-Seidel/Breaking_Locality_Accelerates_Block_Gauss-Seidel\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Knowledgeable_Reader__Enhancing_Cloze-Style_Reading_Comprehension_with_External_Commonsense_Knowledge/Knowledgeable_Reader__Enhancing_Cloze-Style_Reading_Comprehension_with_External_Commonsense_Knowledge\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Learning_for_Targeted_Sentiment_Analysis/Joint_Learning_for_Targeted_Sentiment_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Do_Multi-Sense_Embeddings_Improve_Natural_Language_Understanding_/Do_Multi-Sense_Embeddings_Improve_Natural_Language_Understanding_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Looking_for_structure_in_lexical_and_acoustic-prosodic_entrainment_behaviors/Looking_for_structure_in_lexical_and_acoustic-prosodic_entrainment_behaviors\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Problems_in_Current_Text_Simplification_Research__New_Data_Can_Help/Problems_in_Current_Text_Simplification_Research__New_Data_Can_Help\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/From_Patches_to_Images__A_Nonparametric_Generative_Model/From_Patches_to_Images__A_Nonparametric_Generative_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/SciDTB__Discourse_Dependency_TreeBank_for_Scientific_Abstracts/SciDTB__Discourse_Dependency_TreeBank_for_Scientific_Abstracts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Spatio-temporal_Bayesian_On-line_Changepoint_Detection_with_Model_Selection_/Spatio-temporal_Bayesian_On-line_Changepoint_Detection_with_Model_Selection_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Drug_Extraction_from_the_Web__Summarizing_Drug_Experiences_with_Multi-Dimensional_Topic_Models/Drug_Extraction_from_the_Web__Summarizing_Drug_Experiences_with_Multi-Dimensional_Topic_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Understanding_Satirical_Articles_Using_Common-Sense/Understanding_Satirical_Articles_Using_Common-Sense\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Natural_Language_Processing_with_Small_Feed-Forward_Networks/Natural_Language_Processing_with_Small_Feed-Forward_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Equivariance_Through_Parameter-Sharing/Equivariance_Through_Parameter-Sharing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Towards_Decoding_as_Continuous_Optimisation_in_Neural_Machine_Translation/Towards_Decoding_as_Continuous_Optimisation_in_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Integrating_Order_Information_and_Event_Relation_for_Script_Event_Prediction/Integrating_Order_Information_and_Event_Relation_for_Script_Event_Prediction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unsupervised_Cross-lingual_Transfer_of_Word_Embedding_Spaces/Unsupervised_Cross-lingual_Transfer_of_Word_Embedding_Spaces\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Creating_and_Characterizing_a_Diverse_Corpus_of_Sarcasm_in_Dialogue/Creating_and_Characterizing_a_Diverse_Corpus_of_Sarcasm_in_Dialogue\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Predicting_Semantic_Relations_using_Global_Graph_Properties/Predicting_Semantic_Relations_using_Global_Graph_Properties\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Nonparametric_Regression_with_Comparisons__Escaping_the_Curse_of_Dimensionality_with_Ordinal_Information/Nonparametric_Regression_with_Comparisons__Escaping_the_Curse_of_Dimensionality_with_Ordinal_Information\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/High-Dimensional_Variance-Reduced_Stochastic_Gradient_Expectation-Maximization_Algorithm/High-Dimensional_Variance-Reduced_Stochastic_Gradient_Expectation-Maximization_Algorithm\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Collect_at_Once,_Use_Effectively__Making_Non-interactive_Locally_Private_Learning_Possible/Collect_at_Once,_Use_Effectively__Making_Non-interactive_Locally_Private_Learning_Possible\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Transfer_Learning_via_Learning_to_Transfer/Transfer_Learning_via_Learning_to_Transfer\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bootstrapping_into_Filler-Gap__An_Acquisition_Story/Bootstrapping_into_Filler-Gap__An_Acquisition_Story\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Evaluation_of_Word_Vector_Representations_by_Subspace_Alignment/Evaluation_of_Word_Vector_Representations_by_Subspace_Alignment\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/GSOS__Gauss-Seidel_Operator_Splitting_Algorithm_for__Multi-Term_Nonsmooth_Convex_Composite_Optimization/GSOS__Gauss-Seidel_Operator_Splitting_Algorithm_for__Multi-Term_Nonsmooth_Convex_Composite_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Leveraging_distributed_representations_and_lexico-syntactic_fixedness_for_token-level_prediction_of_the_idiomaticity_of_English_verb-noun_combinations/Leveraging_distributed_representations_and_lexico-syntactic_fixedness_for_token-level_prediction_of_the_idiomaticity_of_English_verb-noun_combinations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/End-to-end_Graph-based_TAG_Parsing_with_Neural_Networks/End-to-end_Graph-based_TAG_Parsing_with_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Delete,_Retrieve,_Generate__a_Simple_Approach_to_Sentiment_and_Style_Transfer/Delete,_Retrieve,_Generate__a_Simple_Approach_to_Sentiment_and_Style_Transfer\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Linear_Spectral_Estimators_and_an_Application_to_Phase_Retrieval/Linear_Spectral_Estimators_and_an_Application_to_Phase_Retrieval\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Optimizer_Search_with_Reinforcement_Learning/Neural_Optimizer_Search_with_Reinforcement_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Mining_Inference_Formulas_by_Goal-Directed_Random_Walks/Mining_Inference_Formulas_by_Goal-Directed_Random_Walks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Abstract_Syntax_Networks_for_Code_Generation_and_Semantic_Parsing/Abstract_Syntax_Networks_for_Code_Generation_and_Semantic_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Human_Needs_Categorization_of_Affective_Events_Using_Labeled_and_Unlabeled_Data/Human_Needs_Categorization_of_Affective_Events_Using_Labeled_and_Unlabeled_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Variational_Inference_for_Sparse_and_Undirected_Models/Variational_Inference_for_Sparse_and_Undirected_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Dependent_Relational_Gamma_Process_Models_for_Longitudinal_Networks/Dependent_Relational_Gamma_Process_Models_for_Longitudinal_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/EmoNet__Fine-Grained_Emotion_Detection_with_Gated_Recurrent_Neural_Networks/EmoNet__Fine-Grained_Emotion_Detection_with_Gated_Recurrent_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Generating_Syntactic_Paraphrases/Generating_Syntactic_Paraphrases\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Minimizing_Trust_Leaks_for_Robust_Sybil_Detection/Minimizing_Trust_Leaks_for_Robust_Sybil_Detection\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Text_Generation_in_Stories_Using_Entity_Representations_as_Context/Neural_Text_Generation_in_Stories_Using_Entity_Representations_as_Context\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Markov_Modulated_Gaussian_Cox_Processes_forSemi-Stationary_Intensity_Modeling_of_Events_Data/Markov_Modulated_Gaussian_Cox_Processes_forSemi-Stationary_Intensity_Modeling_of_Events_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Efficient_Distributed_Learning_with_Sparsity/Efficient_Distributed_Learning_with_Sparsity\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Word_Emotion_Induction_for_Multiple_Languages_as_a_Deep_Multi-Task_Learning_Problem/Word_Emotion_Induction_for_Multiple_Languages_as_a_Deep_Multi-Task_Learning_Problem\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Covariate_Adjusted_Precision_Matrix_Estimation_via_Nonconvex_Optimization/Covariate_Adjusted_Precision_Matrix_Estimation_via_Nonconvex_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Generative_Models_for_Relational_Data_with_Side_Information/Deep_Generative_Models_for_Relational_Data_with_Side_Information\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Importance_sampling_for_unbiased_on-demand_evaluation_of_knowledge_base_population/Importance_sampling_for_unbiased_on-demand_evaluation_of_knowledge_base_population\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sentence_Compression_by_Deletion_with_LSTMs/Sentence_Compression_by_Deletion_with_LSTMs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Proportional_Allocation___Simple,_Distributed,_and_Diverse_Matching_with_High_Entropy_/Proportional_Allocation___Simple,_Distributed,_and_Diverse_Matching_with_High_Entropy_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Large-scale_Analysis_of_Counseling_Conversations__An_Application_of_Natural_Language_Processing_to_Mental_Health/Large-scale_Analysis_of_Counseling_Conversations__An_Application_of_Natural_Language_Processing_to_Mental_Health\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Semantic_Parsing_with_Type_Constraints_for_Semi-Structured_Tables/Neural_Semantic_Parsing_with_Type_Constraints_for_Semi-Structured_Tables\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Extreme_Learning_to_Rank_via_Low_Rank_Assumption/Extreme_Learning_to_Rank_via_Low_Rank_Assumption\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Context-Aware_Convolutional_Filters_for_Text_Processing/Learning_Context-Aware_Convolutional_Filters_for_Text_Processing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Scene_Graph_Parsing_as_Dependency_Parsing/Scene_Graph_Parsing_as_Dependency_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Attentive_listening_system_with_backchanneling,_response_generation_and_flexible_turn-taking/Attentive_listening_system_with_backchanneling,_response_generation_and_flexible_turn-taking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Modeling_of_Content_and_Discourse_Relations_in_Dialogues/Joint_Modeling_of_Content_and_Discourse_Relations_in_Dialogues\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Asymmetric_Tri-training_for_Unsupervised_Domain_Adaptation/Asymmetric_Tri-training_for_Unsupervised_Domain_Adaptation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_How_to_Actively_Learn__A_Deep_Imitation_Learning_Approach/Learning_How_to_Actively_Learn__A_Deep_Imitation_Learning_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Exploring_the_Role_of_Prior_Beliefs_for_Argument_Persuasion/Exploring_the_Role_of_Prior_Beliefs_for_Argument_Persuasion\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Understanding_Generalization_and_Optimization_Performance_of_Deep_CNNs/Understanding_Generalization_and_Optimization_Performance_of_Deep_CNNs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Compiling_Combinatorial_Prediction_Games/Compiling_Combinatorial_Prediction_Games\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Comprehensive_Supersense_Disambiguation_of_English_Prepositions_and_Possessives/Comprehensive_Supersense_Disambiguation_of_English_Prepositions_and_Possessives\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Probabilistic_Boolean_Tensor_Decomposition/Probabilistic_Boolean_Tensor_Decomposition\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Representations_of_language_in_a_model_of_visually_grounded_speech_signal/Representations_of_language_in_a_model_of_visually_grounded_speech_signal\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Unsupervised_Probability_Model_for_Speech-to-Translation_Alignment_of_Low-Resource_Languages/An_Unsupervised_Probability_Model_for_Speech-to-Translation_Alignment_of_Low-Resource_Languages\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Make_the_Minority_Great_Again___First-Order_Regret_Bound_for_Contextual_Bandits/Make_the_Minority_Great_Again___First-Order_Regret_Bound_for_Contextual_Bandits\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Yes,_but_Did_It_Work__Evaluating_Variational_Inference/Yes,_but_Did_It_Work__Evaluating_Variational_Inference\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Tabular_Method_for_Dynamic_Oracles_in_Transition-Based_Parsing/A_Tabular_Method_for_Dynamic_Oracles_in_Transition-Based_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/CoSimRank__A_Flexible___Efficient_Graph-Theoretic_Similarity_Measure/CoSimRank__A_Flexible___Efficient_Graph-Theoretic_Similarity_Measure\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Pyramid_Convolutional_Neural_Networks_for_Text_Categorization/Deep_Pyramid_Convolutional_Neural_Networks_for_Text_Categorization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Best_of_Both_Worlds__Combining_Recent_Advances_in_Neural_Machine_Translation/The_Best_of_Both_Worlds__Combining_Recent_Advances_in_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarially_Regularized_Autoencoders/Adversarially_Regularized_Autoencoders\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Discourse-level_Diversity_for_Neural_Dialog_Models_using_Conditional_Variational_Autoencoders/Learning_Discourse-level_Diversity_for_Neural_Dialog_Models_using_Conditional_Variational_Autoencoders\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Tropical_Geometry_of_Deep_Neural_Networks/Tropical_Geometry_of_Deep_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Evaluating_Spoken_Dialogue_Processing_for_Time-Offset_Interaction/Evaluating_Spoken_Dialogue_Processing_for_Time-Offset_Interaction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Dynamic_Oracles_for_Top-Down_and_In-Order_Shift-Reduce_Constituent_Parsing/Dynamic_Oracles_for_Top-Down_and_In-Order_Shift-Reduce_Constituent_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Multi-Task_Learning_for_Aspect_Term_Extraction_with_Memory_Interaction/Deep_Multi-Task_Learning_for_Aspect_Term_Extraction_with_Memory_Interaction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Temporal-Recurrent-Replicated-Softmax_for_Topical_Trends_over_Time/Deep_Temporal-Recurrent-Replicated-Softmax_for_Topical_Trends_over_Time\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Approaching_Neural_Grammatical_Error_Correction_as_a_Low-Resource_Machine_Translation_Task/Approaching_Neural_Grammatical_Error_Correction_as_a_Low-Resource_Machine_Translation_Task\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Online_Segment_to_Segment_Neural_Transduction/Online_Segment_to_Segment_Neural_Transduction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Distributed_and_Provably_Good_Seedings_for_k-Means_in_Constant_Rounds/Distributed_and_Provably_Good_Seedings_for_k-Means_in_Constant_Rounds\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Word_Segmentation_with_Rich_Pretraining/Neural_Word_Segmentation_with_Rich_Pretraining\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Maximum_Margin_Reward_Networks_for_Learning_from_Explicit_and_Implicit_Supervision/Maximum_Margin_Reward_Networks_for_Learning_from_Explicit_and_Implicit_Supervision\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Towards_Black-box_Iterative_Machine_Teaching/Towards_Black-box_Iterative_Machine_Teaching\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Dual_Fixed-Size_Ordinally_Forgetting_Encoding_(FOFE)_for_Competitive_Neural_Language_Models/Dual_Fixed-Size_Ordinally_Forgetting_Encoding_(FOFE)_for_Competitive_Neural_Language_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Estimating_individual_treatment_effect__generalization_bounds_and_algorithms/Estimating_individual_treatment_effect__generalization_bounds_and_algorithms\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Neural_Model_of_Adaptation_in_Reading/A_Neural_Model_of_Adaptation_in_Reading\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Co-Matching_Model_for_Multi-choice_Reading_Comprehension/A_Co-Matching_Model_for_Multi-choice_Reading_Comprehension\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Fast_Information-theoretic_Bayesian_Optimisation/Fast_Information-theoretic_Bayesian_Optimisation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Cogent__A_Generic_Dialogue_System_Shell_Based_on_a_Collaborative_Problem_Solving_Model/Cogent__A_Generic_Dialogue_System_Shell_Based_on_a_Collaborative_Problem_Solving_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Algorithmic_Stability_and_Hypothesis_Complexity/Algorithmic_Stability_and_Hypothesis_Complexity\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Uniform_Convergence_Rates_for_Kernel_Density_Estimation/Uniform_Convergence_Rates_for_Kernel_Density_Estimation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deal_or_No_Deal__End-to-End_Learning_for_Negotiation_Dialogues/Deal_or_No_Deal__End-to-End_Learning_for_Negotiation_Dialogues\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Automatic_Discovery_of_the_Statistical_Types_of_Variables_in_a_Dataset/Automatic_Discovery_of_the_Statistical_Types_of_Variables_in_a_Dataset\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Iterative_Amortized_Inference/Iterative_Amortized_Inference\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/TWOWINGOS__A_Two-Wing_Optimization_Strategy_for_Evidential_Claim_Verification/TWOWINGOS__A_Two-Wing_Optimization_Strategy_for_Evidential_Claim_Verification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Maximum-A-Posteriori_Perturbation_Models_for_Structured_Prediction_in_Polynomial_Time/Learning_Maximum-A-Posteriori_Perturbation_Models_for_Structured_Prediction_in_Polynomial_Time\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Laplacian_Framework_for_Option_Discovery_in_Reinforcement_Learning/A_Laplacian_Framework_for_Option_Discovery_in_Reinforcement_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Two_Methods_for_Domain_Adaptation_of_Bilingual_Tasks__Delightfully_Simple_and_Broadly_Applicable/Two_Methods_for_Domain_Adaptation_of_Bilingual_Tasks__Delightfully_Simple_and_Broadly_Applicable\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Structured_Output_Learning_with_Abstention__Application_to_Accurate_Opinion_Prediction/Structured_Output_Learning_with_Abstention__Application_to_Accurate_Opinion_Prediction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sample-efficient_Actor-Critic_Reinforcement_Learning_with_Supervised_Data_for_Dialogue_Management/Sample-efficient_Actor-Critic_Reinforcement_Learning_with_Supervised_Data_for_Dialogue_Management\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Just-In-Time_Keyword_Extraction_from_Meeting_Transcripts/A_Just-In-Time_Keyword_Extraction_from_Meeting_Transcripts\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Failures_of_Gradient-Based_Deep_Learning/Failures_of_Gradient-Based_Deep_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/What_Your_Username_Says_About_You/What_Your_Username_Says_About_You\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Deep_Architectures_via_Generalized_Whitened_Neural_Networks/Learning_Deep_Architectures_via_Generalized_Whitened_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Knowledge_Completion_for_Generics_using_Guided_Tensor_Factorization/Knowledge_Completion_for_Generics_using_Guided_Tensor_Factorization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Ubuntu_Dialogue_Corpus__A_Large_Dataset_for_Research_in_Unstructured_Multi-Turn_Dialogue_Systems/The_Ubuntu_Dialogue_Corpus__A_Large_Dataset_for_Research_in_Unstructured_Multi-Turn_Dialogue_Systems\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Towards_Less_Generic_Responses_in_Neural_Conversation_Models__A_Statistical_Re-weighting_Method/Towards_Less_Generic_Responses_in_Neural_Conversation_Models__A_Statistical_Re-weighting_Method\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Dynamics_of_Learning__A_Random_Matrix_Approach/The_Dynamics_of_Learning__A_Random_Matrix_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Semi-supervised_User_Geolocation_via_Graph_Convolutional_Networks/Semi-supervised_User_Geolocation_via_Graph_Convolutional_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Personalizing_Dialogue_Agents__I_have_a_dog,_do_you_have_pets_too_/Personalizing_Dialogue_Agents__I_have_a_dog,_do_you_have_pets_too_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Hybrid_Convolutional_Variational_Autoencoder_for_Text_Generation/A_Hybrid_Convolutional_Variational_Autoencoder_for_Text_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sequence_to_Better_Sequence__Continuous_Revision_of_Combinatorial_Structures/Sequence_to_Better_Sequence__Continuous_Revision_of_Combinatorial_Structures\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Statistical_Machine_Translation_with_a_Multilingual_Paraphrase_Database/Improving_Statistical_Machine_Translation_with_a_Multilingual_Paraphrase_Database\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Identifying_Semantic_Edit_Intentions_from_Revisions_in_Wikipedia/Identifying_Semantic_Edit_Intentions_from_Revisions_in_Wikipedia\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Not_All_Dialogues_are_Created_Equal__Instance_Weighting_for_Neural_Conversational_Models/Not_All_Dialogues_are_Created_Equal__Instance_Weighting_for_Neural_Conversational_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Evaluating_Bayesian_Models_with_Posterior_Dispersion_Indices/Evaluating_Bayesian_Models_with_Posterior_Dispersion_Indices\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Exploring_Neural_Text_Simplification_Models/Exploring_Neural_Text_Simplification_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Step-wise_Usage-based_Method_for_Inducing_Polysemy-aware_Verb_Classes/A_Step-wise_Usage-based_Method_for_Inducing_Polysemy-aware_Verb_Classes\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/AMR-to-text_Generation_with_Synchronous_Node_Replacement_Grammar/AMR-to-text_Generation_with_Synchronous_Node_Replacement_Grammar\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Investigating_Capsule_Networks_with_Dynamic_Routing_for_Text_Classification/Investigating_Capsule_Networks_with_Dynamic_Routing_for_Text_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Approximate_Steepest_Coordinate_Descent/Approximate_Steepest_Coordinate_Descent\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Corpus_of_Sentence-level_Revisions_in_Academic_Writing__A_Step_towards_Understanding_Statement_Strength_in_Communication/A_Corpus_of_Sentence-level_Revisions_in_Academic_Writing__A_Step_towards_Understanding_Statement_Strength_in_Communication\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Low-Dimensional_Temporal_Representations/Learning_Low-Dimensional_Temporal_Representations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Explicit_Inductive_Bias_for_Transfer_Learning_with_Convolutional_Networks/Explicit_Inductive_Bias_for_Transfer_Learning_with_Convolutional_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Citation_Resolution__A_method_for_evaluating_context-based_citation_recommendation_systems/Citation_Resolution__A_method_for_evaluating_context-based_citation_recommendation_systems\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Conversational_Image_Editing__Incremental_Intent_Identification_in_a_New_Dialogue_Task/Conversational_Image_Editing__Incremental_Intent_Identification_in_a_New_Dialogue_Task\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Retrieval-Based_Neural_Code_Generation/Retrieval-Based_Neural_Code_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Invariance_of_Weight_Distributions_in_Rectified_MLPs/Invariance_of_Weight_Distributions_in_Rectified_MLPs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/DialSQL__Dialogue_Based_Structured_Query_Generation/DialSQL__Dialogue_Based_Structured_Query_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Parseval_Networks__Improving_Robustness_to_Adversarial_Examples/Parseval_Networks__Improving_Robustness_to_Adversarial_Examples\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Generalized_Agreement_for_Bidirectional_Word_Alignment/Generalized_Agreement_for_Bidirectional_Word_Alignment\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/SQL-to-Text_Generation_with_Graph-to-Sequence_Model/SQL-to-Text_Generation_with_Graph-to-Sequence_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Role_of_Conversation_Context_for_Sarcasm_Detection_in_Online_Interactions/The_Role_of_Conversation_Context_for_Sarcasm_Detection_in_Online_Interactions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multimodal_Frame_Identification_with_Multilingual_Evaluation/Multimodal_Frame_Identification_with_Multilingual_Evaluation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_in_POMDPs_with_Monte_Carlo_Tree_Search/Learning_in_POMDPs_with_Monte_Carlo_Tree_Search\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Decoding_Anagrammed_Texts_Written_in_an_Unknown_Language_and_Script/Decoding_Anagrammed_Texts_Written_in_an_Unknown_Language_and_Script\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Cross-lingual_Opinion_Analysis_via_Negative_Transfer_Detection/Cross-lingual_Opinion_Analysis_via_Negative_Transfer_Detection\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Diversity_driven_attention_model_for_query-based_abstractive_summarization/Diversity_driven_attention_model_for_query-based_abstractive_summarization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Linguistically-Informed_Self-Attention_for_Semantic_Role_Labeling/Linguistically-Informed_Self-Attention_for_Semantic_Role_Labeling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Comment-to-Article_Linking_in_the_Online_News_Domain/Comment-to-Article_Linking_in_the_Online_News_Domain\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reduced_Space_and_Faster_Convergence_in_Imperfect-Information_Games_via_Pruning/Reduced_Space_and_Faster_Convergence_in_Imperfect-Information_Games_via_Pruning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bayesian_Model_Selection_for_Change_Point_Detection_and_Clustering/Bayesian_Model_Selection_for_Change_Point_Detection_and_Clustering\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Translating_Neuralese/Translating_Neuralese\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Hierarchical_Neural_Story_Generation/Hierarchical_Neural_Story_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Rapid_Adaptation_of_Neural_Machine_Translation_to_New_Languages/Rapid_Adaptation_of_Neural_Machine_Translation_to_New_Languages\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Simplifying_Neural_Machine_Translation_with_Addition-Subtraction_Twin-Gated_Recurrent_Networks/Simplifying_Neural_Machine_Translation_with_Addition-Subtraction_Twin-Gated_Recurrent_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Morphological_Modeling_for_Machine_Translation_of_English-Iraqi_Arabic_Spoken_Dialogs/Morphological_Modeling_for_Machine_Translation_of_English-Iraqi_Arabic_Spoken_Dialogs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Feasible_Arm_Identification/Feasible_Arm_Identification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Program_Induction_by_Rationale_Generation__Learning_to_Solve_and_Explain_Algebraic_Word_Problems/Program_Induction_by_Rationale_Generation__Learning_to_Solve_and_Explain_Algebraic_Word_Problems\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Regret_Minimization_for_Partially_Observable_Deep_Reinforcement_Learning/Regret_Minimization_for_Partially_Observable_Deep_Reinforcement_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Who_did_What__A_Large-Scale_Person-Centered_Cloze_Dataset/Who_did_What__A_Large-Scale_Person-Centered_Cloze_Dataset\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_State_of_the_Art_in_Semantic_Representation/The_State_of_the_Art_in_Semantic_Representation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/HOTPOTQA__A_Dataset_for_Diverse,_Explainable_Multi-hop_Question_Answering/HOTPOTQA__A_Dataset_for_Diverse,_Explainable_Multi-hop_Question_Answering\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Learning_for_Emotion_Classification_and_Emotion_Cause_Detection/Joint_Learning_for_Emotion_Classification_and_Emotion_Cause_Detection\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_University_of_Alicante_at_MultiLing_2015__approach,_results_and_further_insights/The_University_of_Alicante_at_MultiLing_2015__approach,_results_and_further_insights\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Projection-free_Distributed_Online_Learning_in_Networks/Projection-free_Distributed_Online_Learning_in_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_contextualized_word_representations/Deep_contextualized_word_representations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Frames__A_Corpus_for_Adding_Memory_to_Goal-Oriented_Dialogue_Systems/Frames__A_Corpus_for_Adding_Memory_to_Goal-Oriented_Dialogue_Systems\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Variational_Policy_for_Guiding_Point_Processes/Variational_Policy_for_Guiding_Point_Processes\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unsupervised_Discrete_Sentence_Representation_Learning_for_Interpretable_Neural_Dialog_Generation/Unsupervised_Discrete_Sentence_Representation_Learning_for_Interpretable_Neural_Dialog_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_to_Aggregate_Ordinal_Labels_by_Maximizing_Separating_Width/Learning_to_Aggregate_Ordinal_Labels_by_Maximizing_Separating_Width\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Fake_News_Mitigation_via_Point_Process_Based_Intervention/Fake_News_Mitigation_via_Point_Process_Based_Intervention\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deeper_Attention_to_Abusive_User_Content_Moderation/Deeper_Attention_to_Abusive_User_Content_Moderation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Lexical_Event_Ordering_with_an_Edge-Factored_Model/Lexical_Event_Ordering_with_an_Edge-Factored_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Knowledge_Base_Inference_using_Bridging_Entities/Knowledge_Base_Inference_using_Bridging_Entities\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Alignment_at_Work__Using_Language_to_Distinguish_the_Internalization_and_Self-Regulation_Components_of_Cultural_Fit_in_Organizations/Alignment_at_Work__Using_Language_to_Distinguish_the_Internalization_and_Self-Regulation_Components_of_Cultural_Fit_in_Organizations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Incorporating_Dialectal_Variability_for_Socially_Equitable_Language_Identification/Incorporating_Dialectal_Variability_for_Socially_Equitable_Language_Identification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Name_List_Only__Target_Entity_Disambiguation_in_Short_Texts/Name_List_Only__Target_Entity_Disambiguation_in_Short_Texts\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Local_Density_Estimation_in_High_Dimensions/Local_Density_Estimation_in_High_Dimensions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/From_Paraphrase_Database_to_Compositional_Paraphrase_Model_and_Back/From_Paraphrase_Database_to_Compositional_Paraphrase_Model_and_Back\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/MentorNet__Learning_Data-Driven_Curriculum_for_Very_Deep_Neural_Networks_on_Corrupted_Labels/MentorNet__Learning_Data-Driven_Curriculum_for_Very_Deep_Neural_Networks_on_Corrupted_Labels\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reasoning_about_Pragmatics_with_Neural_Listeners_and_Speakers/Reasoning_about_Pragmatics_with_Neural_Listeners_and_Speakers\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_from_Clinical_Judgments__Semi-Markov-Modulated_Marked__Hawkes_Processes_for_Risk_Prognosis/Learning_from_Clinical_Judgments__Semi-Markov-Modulated_Marked__Hawkes_Processes_for_Risk_Prognosis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Dimensionality_Reduction_and_Metric_Learning__A_Geometric_Take/Joint_Dimensionality_Reduction_and_Metric_Learning__A_Geometric_Take\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Gradient_Coding__Avoiding_Stragglers_in_Distributed_Learning/Gradient_Coding__Avoiding_Stragglers_in_Distributed_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarial_Multi-task_Learning_for_Text_Classification/Adversarial_Multi-task_Learning_for_Text_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Detecting_Institutional_Dialog_Acts_in_Police_Traffic_Stops/Detecting_Institutional_Dialog_Acts_in_Police_Traffic_Stops\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Determinantal_Point_Processes_with_Moments_and_Cycles/Learning_Determinantal_Point_Processes_with_Moments_and_Cycles\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unsupervised_Grammar_Induction_with_Depth-bounded_PCFG/Unsupervised_Grammar_Induction_with_Depth-bounded_PCFG\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Web_as_a_Knowledge-base_for_Answering_Complex_Questions/The_Web_as_a_Knowledge-base_for_Answering_Complex_Questions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_to_Explain__An_Information-Theoretic_Perspective__on_Model_Interpretation/Learning_to_Explain__An_Information-Theoretic_Perspective__on_Model_Interpretation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Aspect_Level_Sentiment_Classification_with_Deep_Memory_Network/Aspect_Level_Sentiment_Classification_with_Deep_Memory_Network\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Exploiting_Cross-Sentence_Context_for_Neural_Machine_Translation/Exploiting_Cross-Sentence_Context_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Meaning-based_Statistical_English_Math_Word_Problem_Solver/A_Meaning-based_Statistical_English_Math_Word_Problem_Solver\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Empirical_comparison_of_dependency_conversions_for_RST_discourse_trees/Empirical_comparison_of_dependency_conversions_for_RST_discourse_trees\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stronger_Generalization_Bounds_for_Deep_Nets_via_a_Compression_Approach/Stronger_Generalization_Bounds_for_Deep_Nets_via_a_Compression_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Boo(n)_for_Evaluating_Architecture_Performance/A_Boo(n)_for_Evaluating_Architecture_Performance\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Towards_a_Discourse_Relation-aware_Approach_for_Chinese-English_Machine_Translation/Towards_a_Discourse_Relation-aware_Approach_for_Chinese-English_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Coming_to_Your_Senses__on_Controls_and_Evaluation_Sets_in_Polysemy_Research/Coming_to_Your_Senses__on_Controls_and_Evaluation_Sets_in_Polysemy_Research\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Toward_Controlled_Generation_of_Text/Toward_Controlled_Generation_of_Text\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Composing_Tree_Graphical_Models_with_Persistent_Homology_Features_for_Clustering_Mixed-Type_Data/Composing_Tree_Graphical_Models_with_Persistent_Homology_Features_for_Clustering_Mixed-Type_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Abstractive_Document_Summarization_with_a_Graph-Based_Attentional_Neural_Model/Abstractive_Document_Summarization_with_a_Graph-Based_Attentional_Neural_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unsupervised_Timeline_Generation_for_Wikipedia_History_Articles/Unsupervised_Timeline_Generation_for_Wikipedia_History_Articles\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Language-Guided_Adaptive_Perception_for_Efficient_Grounded_Communication_with_Robotic_Manipulators_in_Cluttered_Environments/Language-Guided_Adaptive_Perception_for_Efficient_Grounded_Communication_with_Robotic_Manipulators_in_Cluttered_Environments\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Strong_Baselines_for_Simple_Question_Answering_over_Knowledge_Graphs_with_and_without_Neural_Networks/Strong_Baselines_for_Simple_Question_Answering_over_Knowledge_Graphs_with_and_without_Neural_Networks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Semantic_Composition_to_Detect_Non-compositionality_of_Multiword_Expressions/Learning_Semantic_Composition_to_Detect_Non-compositionality_of_Multiword_Expressions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Prediction_Rule_Reshaping/Prediction_Rule_Reshaping\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Efficient_Contextualized_Representation__Language_Model_Pruning_for_Sequence_Labeling/Efficient_Contextualized_Representation__Language_Model_Pruning_for_Sequence_Labeling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Toward_Zero-shot_Entity_Recognition_in_Task-oriented_Conversational_Agents/Toward_Zero-shot_Entity_Recognition_in_Task-oriented_Conversational_Agents\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Rule_Extraction_for_Tree-to-Tree_Transducers_by_Cost_Minimization/Rule_Extraction_for_Tree-to-Tree_Transducers_by_Cost_Minimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Scientific_Article_Summarization_Using_Citation-Context_and_Article_s_Discourse_Structure/Scientific_Article_Summarization_Using_Citation-Context_and_Article_s_Discourse_Structure\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Concept_Learning_and_Semantic_Parsing_from_Natural_Language_Explanations/Joint_Concept_Learning_and_Semantic_Parsing_from_Natural_Language_Explanations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Noise2Noise__Learning_Image_Restoration_without_Clean_Data/Noise2Noise__Learning_Image_Restoration_without_Clean_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Predicting_accuracy_on_large_datasets_from_smaller_pilot_data/Predicting_accuracy_on_large_datasets_from_smaller_pilot_data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Scaling_Up_Sparse_Support_Vector_Machinesby_Simultaneous_Feature_and_Sample_Reduction/Scaling_Up_Sparse_Support_Vector_Machinesby_Simultaneous_Feature_and_Sample_Reduction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Document_Embedding_Enhanced_Event_Detection_with_Hierarchical_and_Supervised_Attention/Document_Embedding_Enhanced_Event_Detection_with_Hierarchical_and_Supervised_Attention\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Discrete_Representations_via_Information_Maximizing_Self-Augmented_Training/Learning_Discrete_Representations_via_Information_Maximizing_Self-Augmented_Training\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Modeling_of_Topics,_Citations,_and_Topical_Authority_in_Academic_Corpora/Joint_Modeling_of_Topics,_Citations,_and_Topical_Authority_in_Academic_Corpora\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Topic_Memory_Networks_for_Short_Text_Classification/Topic_Memory_Networks_for_Short_Text_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Building_compositional_semantics_and_higher-order_inference_system_for_a_wide-coverage_Japanese_CCG_parser/Building_compositional_semantics_and_higher-order_inference_system_for_a_wide-coverage_Japanese_CCG_parser\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multiple_Instance_Learning_Networks_for_Fine-Grained_Sentiment_Analysis/Multiple_Instance_Learning_Networks_for_Fine-Grained_Sentiment_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Language_Modeling_with_Gated_Convolutional_Networks/Language_Modeling_with_Gated_Convolutional_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation/A_Binarized_Neural_Network_Joint_Model_for_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/SCDV___Sparse_Composite_Document_Vectors_using_soft_clustering_over_distributional_representations/SCDV___Sparse_Composite_Document_Vectors_using_soft_clustering_over_distributional_representations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Geodesic_Convolutional_Shape_Optimization/Geodesic_Convolutional_Shape_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Neural_Message_Passing_for_Quantum_Chemistry/Neural_Message_Passing_for_Quantum_Chemistry\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/What_Makes_Reading_Comprehension_Questions_Easier_/What_Makes_Reading_Comprehension_Questions_Easier_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Argument_Mining_with_Structured_SVMs_and_RNNs/Argument_Mining_with_Structured_SVMs_and_RNNs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/C3EL__A_Joint_Model_for_Cross-Document_Co-Reference_Resolution_and_Entity_Linking/C3EL__A_Joint_Model_for_Cross-Document_Co-Reference_Resolution_and_Entity_Linking\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unpaired_Sentiment-to-Sentiment_Translation__A_Cycled_Reinforcement_Learning_Approach/Unpaired_Sentiment-to-Sentiment_Translation__A_Cycled_Reinforcement_Learning_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/End-to-end_Active_Object_Tracking_via_Reinforcement_Learning/End-to-end_Active_Object_Tracking_via_Reinforcement_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Out-of-sample_extension_of_graph_adjacency_spectral_embedding/Out-of-sample_extension_of_graph_adjacency_spectral_embedding\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reference_Resolution_in_Situated_Dialogue_with_Learned_Semantics/Reference_Resolution_in_Situated_Dialogue_with_Learned_Semantics\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarial_Example_Generation_with_Syntactically_Controlled_Paraphrase_Networks/Adversarial_Example_Generation_with_Syntactically_Controlled_Paraphrase_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Device_Placement_Optimization_with_Reinforcement_Learning/Device_Placement_Optimization_with_Reinforcement_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Lexical_Choice_in_Neural_Machine_Translation/Improving_Lexical_Choice_in_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bucket_Renormalization_for_Approximate_Inference/Bucket_Renormalization_for_Approximate_Inference\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Probabilistic_Recurrent_State-Space_Models/Probabilistic_Recurrent_State-Space_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Document-Level_Multi-Aspect_Sentiment_Classification_as_Machine_Comprehension/Document-Level_Multi-Aspect_Sentiment_Classification_as_Machine_Comprehension\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Detecting_Perspectives_in_Political_Debates/Detecting_Perspectives_in_Political_Debates\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Equivalence_of_Multicategory_SVM_and_Simplex_Cone_SVM___Fast_Computations_and_Statistical_Theory/Equivalence_of_Multicategory_SVM_and_Simplex_Cone_SVM___Fast_Computations_and_Statistical_Theory\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Combined_Group_and_Exclusive_Sparsity_for_Deep_Neural_Networks/Combined_Group_and_Exclusive_Sparsity_for_Deep_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Friendships,_Rivalries,_and_Trysts__Characterizing_Relations_between_Ideas_in_Texts/Friendships,_Rivalries,_and_Trysts__Characterizing_Relations_between_Ideas_in_Texts\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Count-Based_Exploration_with_Neural_Density_Models/Count-Based_Exploration_with_Neural_Density_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Dataset_and_Evaluation_Metrics_for_Abstractive_Compression_of_Sentences_and_Short_Paragraphs/A_Dataset_and_Evaluation_Metrics_for_Abstractive_Compression_of_Sentences_and_Short_Paragraphs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Near_Human-Level_Performance_in_Grammatical_Error_Correction_with_Hybrid_Machine_Translation/Near_Human-Level_Performance_in_Grammatical_Error_Correction_with_Hybrid_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/diaNED__Time-Aware_Named_Entity_Disambiguation_for_Diachronic_Corpora/diaNED__Time-Aware_Named_Entity_Disambiguation_for_Diachronic_Corpora\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Clustering_Semi-Random_Mixtures_of_Gaussians/Clustering_Semi-Random_Mixtures_of_Gaussians\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Whodunnit__Crime_Drama_as_a_Case_for_Natural_Language_Understanding/Whodunnit__Crime_Drama_as_a_Case_for_Natural_Language_Understanding\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Cross-Sentence_N_-ary_Relation_Extraction_with_Graph_LSTMs/Cross-Sentence_N_-ary_Relation_Extraction_with_Graph_LSTMs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Simulated_Annealing_Based_Inexact_Oracle_for_Wasserstein_Loss_Minimization/A_Simulated_Annealing_Based_Inexact_Oracle_for_Wasserstein_Loss_Minimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Knowledge_Graph_Embedding_with_Hierarchical_Relation_Structure/Knowledge_Graph_Embedding_with_Hierarchical_Relation_Structure\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Biography-Dependent_Collaborative_Entity_Archiving_for_Slot_Filling/Biography-Dependent_Collaborative_Entity_Archiving_for_Slot_Filling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Syntax-based_Rewriting_for_Simultaneous_Machine_Translation/Syntax-based_Rewriting_for_Simultaneous_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Network_Global_Testing_by_Counting_Graphlets/Network_Global_Testing_by_Counting_Graphlets\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Creating_a_Large_Benchmark_for_Open_Information_Extraction/Creating_a_Large_Benchmark_for_Open_Information_Extraction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Approximation-Aware_Dependency_Parsing_by_Belief_Propagation/Approximation-Aware_Dependency_Parsing_by_Belief_Propagation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/POLY__Mining_Relational_Paraphrases_from_Multilingual_Sentences/POLY__Mining_Relational_Paraphrases_from_Multilingual_Sentences\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bilingually-constrained_Synthetic_Data_for_Implicit_Discourse_Relation_Recognition/Bilingually-constrained_Synthetic_Data_for_Implicit_Discourse_Relation_Recognition\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Exploring_Recombination_for_Efficient_Decoding_of_Neural_Machine_Translation/Exploring_Recombination_for_Efficient_Decoding_of_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Important_Features_Through_Propagating_Activation_Differences/Learning_Important_Features_Through_Propagating_Activation_Differences\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Knowledge_Graph_Embedding_Using_Simple_Constraints/Improving_Knowledge_Graph_Embedding_Using_Simple_Constraints\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Personalized_Review_Generation_by_Expanding_Phrases_and_Attending_on_Aspect-Aware_Representations/Personalized_Review_Generation_by_Expanding_Phrases_and_Attending_on_Aspect-Aware_Representations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/StingyCD__Safely_Avoiding_Wasteful_Updates_in_Coordinate_Descent/StingyCD__Safely_Avoiding_Wasteful_Updates_in_Coordinate_Descent\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Judicious_Selection_of_Training_Data_in_Assisting_Language_for_Multilingual_Neural_NER/Judicious_Selection_of_Training_Data_in_Assisting_Language_for_Multilingual_Neural_NER\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/On_the_Spectrum_of_Random_Features_Maps_of_High_Dimensional_Data/On_the_Spectrum_of_Random_Features_Maps_of_High_Dimensional_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Efficient_and_Expressive_Knowledge_Base_Completion_Using_Subgraph_Feature_Extraction/Efficient_and_Expressive_Knowledge_Base_Completion_Using_Subgraph_Feature_Extraction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Large-Scale_QA-SRL_Parsing/Large-Scale_QA-SRL_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Temporal_Information_Extraction_by_Predicting_Relative_Time-lines/Temporal_Information_Extraction_by_Predicting_Relative_Time-lines\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Gradient_Monomial_Gamma_Sampler/Stochastic_Gradient_Monomial_Gamma_Sampler\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Abstract_Meaning_Representation_Parsing_using_LSTM_Recurrent_Neural_Networks/Abstract_Meaning_Representation_Parsing_using_LSTM_Recurrent_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Batch_IS_NOT_Heavy__Learning_Word_Representations_From_All_Samples/Batch_IS_NOT_Heavy__Learning_Word_Representations_From_All_Samples\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Examining_Temporality_in_Document_Classification/Examining_Temporality_in_Document_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/ELDEN__Improved_Entity_Linking_Using_Densified_Knowledge_Graphs/ELDEN__Improved_Entity_Linking_Using_Densified_Knowledge_Graphs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Generic_Sentence_Representations_Using_Convolutional_Neural_Networks/Learning_Generic_Sentence_Representations_Using_Convolutional_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Style_Transfer_Through_Back-Translation/Style_Transfer_Through_Back-Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Adaptive_Test_of_Independence_with_Analytic_Kernel_Embeddings/An_Adaptive_Test_of_Independence_with_Analytic_Kernel_Embeddings\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Relevance_Ranking_Using_Enhanced_Document-Query_Interactions/Deep_Relevance_Ranking_Using_Enhanced_Document-Query_Interactions\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Viterbi_is_Hard__Better_Runtimes_Imply_Faster_Clique_Algorithms/Improving_Viterbi_is_Hard__Better_Runtimes_Imply_Faster_Clique_Algorithms\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/From_Language_to_Programs__Bridging_Reinforcement_Learning_and_Maximum_Marginal_Likelihood/From_Language_to_Programs__Bridging_Reinforcement_Learning_and_Maximum_Marginal_Likelihood\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Lexico-Functional_Patterns_for_First-Person_Affect/Learning_Lexico-Functional_Patterns_for_First-Person_Affect\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Bayesian_Optimization_with_Tree-structured_Dependencies/Bayesian_Optimization_with_Tree-structured_Dependencies\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_a_Neural_Semantic_Parser_by_Counterfactual_Learning_from_Human_Bandit_Feedback/Improving_a_Neural_Semantic_Parser_by_Counterfactual_Learning_from_Human_Bandit_Feedback\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Valency-Augmented_Dependency_Parsing/Valency-Augmented_Dependency_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Semi-Supervised_QA_with_Generative_Domain-Adaptive_Nets/Semi-Supervised_QA_with_Generative_Domain-Adaptive_Nets\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multi-Relational_Question_Answering_from_Narratives__Machine_Reading_and_Reasoning_in_Simulated_Worlds/Multi-Relational_Question_Answering_from_Narratives__Machine_Reading_and_Reasoning_in_Simulated_Worlds\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Iterative,_Sketching-based_Framework_for_Ridge_Regression/An_Iterative,_Sketching-based_Framework_for_Ridge_Regression\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unifying_Text,_Metadata,_and_User_Network_Representations_with_a_Neural_Network_for_Geolocation_Prediction/Unifying_Text,_Metadata,_and_User_Network_Representations_with_a_Neural_Network_for_Geolocation_Prediction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Modified_Equations__and_Adaptive_Stochastic_Gradient_Algorithms/Stochastic_Modified_Equations__and_Adaptive_Stochastic_Gradient_Algorithms\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Spurious_Local_Minima_are_Common_in_Two-Layer_ReLU_Neural_Networks/Spurious_Local_Minima_are_Common_in_Two-Layer_ReLU_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Predicting_News_Headline_Popularity_with_Syntactic_and_Semantic_Knowledge_Using_Multi-Task_Learning/Predicting_News_Headline_Popularity_with_Syntactic_and_Semantic_Knowledge_Using_Multi-Task_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Adaptive_Quasi-Newton_Methods_for_Minimizing_Expected_Values/Stochastic_Adaptive_Quasi-Newton_Methods_for_Minimizing_Expected_Values\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Convergence_Analysis_of_Proximal_Gradient_with_Momentum_for_Nonconvex_Optimization/Convergence_Analysis_of_Proximal_Gradient_with_Momentum_for_Nonconvex_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Kernel_Recursive_ABC__Point_Estimation_with_Intractable_Likelihood/Kernel_Recursive_ABC__Point_Estimation_with_Intractable_Likelihood\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Outta_Control__Laws_of_Semantic_Change_and_Inherent_Biases_in_Word_Representation_Models/Outta_Control__Laws_of_Semantic_Change_and_Inherent_Biases_in_Word_Representation_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/WikiConv__A_Corpus_of_the_Complete_Conversational_History_of_a_Large_Online_Collaborative_Community/WikiConv__A_Corpus_of_the_Complete_Conversational_History_of_a_Large_Online_Collaborative_Community\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Semantic_Role_Labeling_for_Learner_Chinese__the_Importance_of_Syntactic_Parsing_and_L2-L1_Parallel_Data/Semantic_Role_Labeling_for_Learner_Chinese__the_Importance_of_Syntactic_Parsing_and_L2-L1_Parallel_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_a_Mixture_of_Two_Multinomial_Logits/Learning_a_Mixture_of_Two_Multinomial_Logits\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Dual_Supervised_Learning/Dual_Supervised_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Recurrent_Neural_Networks_as_Weighted_Language_Recognizers/Recurrent_Neural_Networks_as_Weighted_Language_Recognizers\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Distributional_and_Orthographic_Aggregation_Model_for_English_Derivational_Morphology/A_Distributional_and_Orthographic_Aggregation_Model_for_English_Derivational_Morphology\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Game-Based_Video-Context_Dialogue/Game-Based_Video-Context_Dialogue\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Document_Modeling_with_Gated_Recurrent_Neural_Network_for_Sentiment_Classification/Document_Modeling_with_Gated_Recurrent_Neural_Network_for_Sentiment_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Junction_Tree_Variational_Autoencoder_for_Molecular_Graph_Generation/Junction_Tree_Variational_Autoencoder_for_Molecular_Graph_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Iterative_Machine_Teaching/Iterative_Machine_Teaching\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Addressing_Objects_and_Their_Relations__The_Conversational_Entity_Dialogue_Model/Addressing_Objects_and_Their_Relations__The_Conversational_Entity_Dialogue_Model\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Context-aware_Learning_for_Sentence-level_Sentiment_Analysis_with_Posterior_Regularization/Context-aware_Learning_for_Sentence-level_Sentiment_Analysis_with_Posterior_Regularization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Capturing_Regional_Variation_with_Distributed_Place_Representations_and_Geographic_Retrofitting/Capturing_Regional_Variation_with_Distributed_Place_Representations_and_Geographic_Retrofitting\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Distributed_Clustering_via_LSH_Based_Data_Partitioning/Distributed_Clustering_via_LSH_Based_Data_Partitioning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Domain_Attention_with_an_Ensemble_of_Experts/Domain_Attention_with_an_Ensemble_of_Experts\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Triangular_Architecture_for_Rare_Language_Translation/Triangular_Architecture_for_Rare_Language_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/TextFlow__A_Text_Similarity_Measure_based_on_Continuous_Sequences/TextFlow__A_Text_Similarity_Measure_based_on_Continuous_Sequences\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Generative_Model_of_Phonotactics/A_Generative_Model_of_Phonotactics\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/SwitchOut__an_Efficient_Data_Augmentation_Algorithm_for_Neural_Machine_Translation/SwitchOut__an_Efficient_Data_Augmentation_Algorithm_for_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Prediction_under_Uncertainty_in_Sparse_Spectrum_Gaussian_Processes__with_Applications_to_Filtering_and_Control/Prediction_under_Uncertainty_in_Sparse_Spectrum_Gaussian_Processes__with_Applications_to_Filtering_and_Control\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Exploiting_Strong_Convexity_from_Data_with_Primal-Dual_First-Order_Algorithms/Exploiting_Strong_Convexity_from_Data_with_Primal-Dual_First-Order_Algorithms\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Black-Box_Variational_Inference_for_Stochastic_Differential_Equations/Black-Box_Variational_Inference_for_Stochastic_Differential_Equations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Distilling_Knowledge_for_Search-based_Structured_Prediction/Distilling_Knowledge_for_Search-based_Structured_Prediction\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Distributional_vectors_encode_referential_attributes/Distributional_vectors_encode_referential_attributes\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Large-Scale_Multi-Domain_Belief_Tracking_with_Knowledge_Sharing/Large-Scale_Multi-Domain_Belief_Tracking_with_Knowledge_Sharing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sequence_Tutor__Conservative_Fine-Tuning_of_Sequence_Generation_Models_with_KL-control/Sequence_Tutor__Conservative_Fine-Tuning_of_Sequence_Generation_Models_with_KL-control\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Entity_Linking_for_Queries_by_Searching_Wikipedia_Sentences/Entity_Linking_for_Queries_by_Searching_Wikipedia_Sentences\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multi-Hop_Knowledge_Graph_Reasoning_with_Reward_Shaping/Multi-Hop_Knowledge_Graph_Reasoning_with_Reward_Shaping\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_word-like_units_from_joint_audio-visual_analysis/Learning_word-like_units_from_joint_audio-visual_analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/BANDITSUM__Extractive_Summarization_as_a_Contextual_Bandit/BANDITSUM__Extractive_Summarization_as_a_Contextual_Bandit\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Tensor_Balancing_on_Statistical_Manifold/Tensor_Balancing_on_Statistical_Manifold\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Differentially_Private_Clustering_in_High-Dimensional_Euclidean_Spaces/Differentially_Private_Clustering_in_High-Dimensional_Euclidean_Spaces\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Part-of-Speech_Tagging_for_Twitter_with_Adversarial_Neural_Networks/Part-of-Speech_Tagging_for_Twitter_with_Adversarial_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Bayesian_Active_Learning_with_Image_Data/Deep_Bayesian_Active_Learning_with_Image_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Conversations_Gone_Awry__Detecting_Early_Signs_of_Conversational_Failure/Conversations_Gone_Awry__Detecting_Early_Signs_of_Conversational_Failure\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Generating_Topical_Poetry/Generating_Topical_Poetry\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Dependency-based_empty_category_detection_via_phrase_structure_trees/Dependency-based_empty_category_detection_via_phrase_structure_trees\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Optimization,_Fast_and_Slow__Optimally_Switching_between_Local_and_Bayesian_Optimization/Optimization,_Fast_and_Slow__Optimally_Switching_between_Local_and_Bayesian_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Key-Value_Memory_Networks_for_Directly_Reading_Documents/Key-Value_Memory_Networks_for_Directly_Reading_Documents\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_La_Carte_Embedding__Cheap_but_Effective_Induction_of_Semantic_Feature_Vectors/A_La_Carte_Embedding__Cheap_but_Effective_Induction_of_Semantic_Feature_Vectors\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Unsupervised_Word-by-Word_Translation_with_Language_Model_and_Denoising_Autoencoder/Improving_Unsupervised_Word-by-Word_Translation_with_Language_Model_and_Denoising_Autoencoder\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Constrained_Interacting_Submodular_Groupings/Constrained_Interacting_Submodular_Groupings\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Position-aware_Attention_and_Supervised_Data_Improve_Slot_Filling/Position-aware_Attention_and_Supervised_Data_Improve_Slot_Filling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Large-Scale_Sparse_Inverse_Covariance_Estimation_via_Thresholding_and_Max-Det_Matrix_Completion/Large-Scale_Sparse_Inverse_Covariance_Estimation_via_Thresholding_and_Max-Det_Matrix_Completion\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/A_Unified_Variance_Reduction-Based_Framework_for_Nonconvex_Low-Rank_Matrix_Recovery/A_Unified_Variance_Reduction-Based_Framework_for_Nonconvex_Low-Rank_Matrix_Recovery\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Phrase-Indexed_Question_Answering__A_New_Challenge_for_Scalable_Document_Comprehension/Phrase-Indexed_Question_Answering__A_New_Challenge_for_Scalable_Document_Comprehension\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Constituent_Parsing_as_Sequence_Labeling/Constituent_Parsing_as_Sequence_Labeling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Gradient_MCMC_Methods_for_Hidden_Markov_Models/Stochastic_Gradient_MCMC_Methods_for_Hidden_Markov_Models\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Closed-form_Marginal_Likelihood_in_Gamma-Poisson_Matrix_Factorization/Closed-form_Marginal_Likelihood_in_Gamma-Poisson_Matrix_Factorization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Pretraining_Sentiment_Classifiers_with_Unlabeled_Dialog_Data/Pretraining_Sentiment_Classifiers_with_Unlabeled_Dialog_Data\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Semi-supervised_Chinese_Word_Segmentation_based_on_Bilingual_Information/Semi-supervised_Chinese_Word_Segmentation_based_on_Bilingual_Information\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Decentralized_Multi-task_Multi-Agent_Reinforcement_Learningunder_Partial_Observability/Deep_Decentralized_Multi-task_Multi-Agent_Reinforcement_Learningunder_Partial_Observability\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Reinforcement_Learning_in_Multi-Party_Trading_Dialog/Reinforcement_Learning_in_Multi-Party_Trading_Dialog\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Policy_Gradient_as_a_Proxy_for_Dynamic_Oracles_in_Constituency_Parsing/Policy_Gradient_as_a_Proxy_for_Dynamic_Oracles_in_Constituency_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Cross-lingual_Distributed_Logical_Representations_for_Semantic_Parsing/Learning_Cross-lingual_Distributed_Logical_Representations_for_Semantic_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Preferential_Bayesian_Optimization/Preferential_Bayesian_Optimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Parsing_with_Traces__An_O(n)_Algorithm_and_a_Structural_Representation/Parsing_with_Traces__An_O(n)_Algorithm_and_a_Structural_Representation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/World_of_Bits__An_Open-Domain_Platform_for_Web-Based_Agents/World_of_Bits__An_Open-Domain_Platform_for_Web-Based_Agents\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Redundancy_Localization_for_the_Conversationalization_of_Unstructured_Responses/Redundancy_Localization_for_the_Conversationalization_of_Unstructured_Responses\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/MEC__Memory-efficient_Convolution_for_Deep_Neural_Network_/MEC__Memory-efficient_Convolution_for_Deep_Neural_Network_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_to_Detect_Sepsis_with_a_Multitask_Gaussian_Process_RNN_Classifier/Learning_to_Detect_Sepsis_with_a_Multitask_Gaussian_Process_RNN_Classifier\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Doubly_Greedy_Primal-Dual_Coordinate_Descent_for_Sparse_Empirical_Risk_Minimization/Doubly_Greedy_Primal-Dual_Coordinate_Descent_for_Sparse_Empirical_Risk_Minimization\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/LEAPSANDBOUNDS__A_Method_for_Approximately_Optimal_Algorithm_Configuration/LEAPSANDBOUNDS__A_Method_for_Approximately_Optimal_Algorithm_Configuration\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Analogical_Inference_for_Multi-relational_Embeddings/Analogical_Inference_for_Multi-relational_Embeddings\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Dynamical_Isometry_and_a_Mean_Field_Theory_of_CNNs__How_to_Train_10,000-Layer_Vanilla_Convolutional_Neural_Networks/Dynamical_Isometry_and_a_Mean_Field_Theory_of_CNNs__How_to_Train_10,000-Layer_Vanilla_Convolutional_Neural_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarial_Feature_Matching_for_Text_Generation/Adversarial_Feature_Matching_for_Text_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Risk_Bounds_for_Transferring_Representations_With_and_Without_Fine-Tuning/Risk_Bounds_for_Transferring_Representations_With_and_Without_Fine-Tuning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/End-to-end_Neural_Coreference_Resolution/End-to-end_Neural_Coreference_Resolution\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Efficient_softmax_approximation_for_GPUs/Efficient_softmax_approximation_for_GPUs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Cross-lingual_Abstract_Meaning_Representation_Parsing/Cross-lingual_Abstract_Meaning_Representation_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Alignment-Based_Compositional_Semantics_for_Instruction_Following/Alignment-Based_Compositional_Semantics_for_Instruction_Following\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/AFET__Automatic_Fine-Grained_Entity_Typing_by_Hierarchical_Partial-Label_Embedding/AFET__Automatic_Fine-Grained_Entity_Typing_by_Hierarchical_Partial-Label_Embedding\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Semantic_Parsing_with_Semi-Supervised_Sequential_Autoencoders/Semantic_Parsing_with_Semi-Supervised_Sequential_Autoencoders\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Mixed_batches_and_symmetric_discriminators_for_GAN_training/Mixed_batches_and_symmetric_discriminators_for_GAN_training\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Mention_Extraction_and_Classification_with_Mention_Hypergraphs/Joint_Mention_Extraction_and_Classification_with_Mention_Hypergraphs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Input_Switched_Affine_Networks__An_RNN_Architecture_Designed_for_Interpretability/Input_Switched_Affine_Networks__An_RNN_Architecture_Designed_for_Interpretability\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Fine-Grained_Prediction_of_Syntactic_Typology__Discovering_Latent_Structure_with_Supervised_Learning/Fine-Grained_Prediction_of_Syntactic_Typology__Discovering_Latent_Structure_with_Supervised_Learning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_to_Prune__Exploring_the_Frontier_of_Fast_and_Accurate_Parsing/Learning_to_Prune__Exploring_the_Frontier_of_Fast_and_Accurate_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Question-Answer_Driven_Semantic_Role_Labeling__Using_Natural_Language_to_Annotate_Natural_Language/Question-Answer_Driven_Semantic_Role_Labeling__Using_Natural_Language_to_Annotate_Natural_Language\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/NeuralREG__An_end-to-end_approach_to_referring_expression_generation/NeuralREG__An_end-to-end_approach_to_referring_expression_generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/TVQA__Localized,_Compositional_Video_Question_Answering/TVQA__Localized,_Compositional_Video_Question_Answering\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multi-Metric_Optimization_Using_Ensemble_Tuning/Multi-Metric_Optimization_Using_Ensemble_Tuning\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Arc-swift__A_Novel_Transition_System_for_Dependency_Parsing/Arc-swift__A_Novel_Transition_System_for_Dependency_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sentiment_Classification_towards_Question-Answering_with_Hierarchical_Matching_Network/Sentiment_Classification_towards_Question-Answering_with_Hierarchical_Matching_Network\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Adversarial_Contrastive_Estimation/Adversarial_Contrastive_Estimation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Not_All_Samples_Are_Created_Equal___Deep_Learning_with_Importance_Sampling/Not_All_Samples_Are_Created_Equal___Deep_Learning_with_Importance_Sampling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Optimal_Distributed_Learning_with_Multi-pass_Stochastic_Gradient_Methods/Optimal_Distributed_Learning_with_Multi-pass_Stochastic_Gradient_Methods\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Zonotope_Hit-and-run_for_Efficient_Sampling_from_Projection_DPPs/Zonotope_Hit-and-run_for_Efficient_Sampling_from_Projection_DPPs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/EQUATION_PARSING___Mapping_Sentences_to_Grounded_Equations/EQUATION_PARSING___Mapping_Sentences_to_Grounded_Equations\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Multi-Task_Learning_with_Shared_Memory_for_Text_Classification/Deep_Multi-Task_Learning_with_Shared_Memory_for_Text_Classification\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Named_Entity_Recognition_and_Disambiguation/Joint_Named_Entity_Recognition_and_Disambiguation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Neural_Templates_for_Text_Generation/Learning_Neural_Templates_for_Text_Generation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Comparing_Computational_Cognitive_Models_of_Generalization_in_a_Language_Acquisition_Task/Comparing_Computational_Cognitive_Models_of_Generalization_in_a_Language_Acquisition_Task\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Data_Summarization_at_Scale_A_Two-Stage_Submodular_Approach/Data_Summarization_at_Scale_A_Two-Stage_Submodular_Approach\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Continuous_Semantic_Representations_of_Symbolic_Expressions/Learning_Continuous_Semantic_Representations_of_Symbolic_Expressions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_Analytical_Formula_of_Population_Gradient_for_two-layered_ReLU_network_and_its_Applications_in_Convergence_and_Critical_Point_Analysis/An_Analytical_Formula_of_Population_Gradient_for_two-layered_ReLU_network_and_its_Applications_in_Convergence_and_Critical_Point_Analysis\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Functional_Gradient_Boosting_based_on_Residual_Network_Perception/Functional_Gradient_Boosting_based_on_Residual_Network_Perception\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Importance_of_Being_Recurrent_for_Modeling_Hierarchical_Structure/The_Importance_of_Being_Recurrent_for_Modeling_Hierarchical_Structure\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep_Learning_in_Semantic_Kernel_Spaces/Deep_Learning_in_Semantic_Kernel_Spaces\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/SparseMAP__Differentiable_Sparse_Structured_Inference/SparseMAP__Differentiable_Sparse_Structured_Inference\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Does_Distributionally_Robust_Supervised_Learning_Give_Robust_Classifiers_/Does_Distributionally_Robust_Supervised_Learning_Give_Robust_Classifiers_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Measuring_Thematic_Fit_with_Distributional_Feature_Overlap/Measuring_Thematic_Fit_with_Distributional_Feature_Overlap\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Improving_Neural_Parsing_by_Disentangling_Model_Combination_and_Reranking_Effects/Improving_Neural_Parsing_by_Disentangling_Model_Combination_and_Reranking_Effects\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Deep-speare__A_joint_neural_model_of_poetic_language,_meter_and_rhyme/Deep-speare__A_joint_neural_model_of_poetic_language,_meter_and_rhyme\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Effective_Approaches_to_Attention-based_Neural_Machine_Translation/Effective_Approaches_to_Attention-based_Neural_Machine_Translation\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Stochastic_Top-k_ListNet/Stochastic_Top-k_ListNet\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/CRAFTML,_an_Efficient_Clustering-based_Random__Forest_for_Extreme_Multi-label_Learning_/CRAFTML,_an_Efficient_Clustering-based_Random__Forest_for_Extreme_Multi-label_Learning_\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Ranking_Distributions_based_on_Noisy_Sorting/Ranking_Distributions_based_on_Noisy_Sorting\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Meritocratic_Fairness_for_Cross-Population_Selection/Meritocratic_Fairness_for_Cross-Population_Selection\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Unfolding_and_Shrinking_Neural_Machine_Translation_Ensembles/Unfolding_and_Shrinking_Neural_Machine_Translation_Ensembles\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Joint_Extraction_of_Entities_and_Relations_Based_on_a_Novel_Tagging_Scheme/Joint_Extraction_of_Entities_and_Relations_Based_on_a_Novel_Tagging_Scheme\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Probabilistic_Typology__Deep_Generative_Models_of_Vowel_Inventories/Probabilistic_Typology__Deep_Generative_Models_of_Vowel_Inventories\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/End-to-End_Learning_for_Structured_Prediction_Energy_Networks/End-to-End_Learning_for_Structured_Prediction_Energy_Networks\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/The_Impact_of_Modeling_Overall_Argumentation_with_Tree_Kernels/The_Impact_of_Modeling_Overall_Argumentation_with_Tree_Kernels\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/An_AMR_Aligner_Tuned_by_Transition-based_Parser/An_AMR_Aligner_Tuned_by_Transition-based_Parser\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Sparse_Non-negative_Matrix_Language_Modeling/Sparse_Non-negative_Matrix_Language_Modeling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Synthetic_Data_Made_to_Order__The_Case_of_Parsing/Synthetic_Data_Made_to_Order__The_Case_of_Parsing\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Learning_Stable_Stochastic_Nonlinear_Dynamical_Systems/Learning_Stable_Stochastic_Nonlinear_Dynamical_Systems\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Large-scale_Semantic_Parsing_without_Question-Answer_Pairs/Large-scale_Semantic_Parsing_without_Question-Answer_Pairs\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Interactive_Learning_from_Policy-Dependent_Human_Feedback/Interactive_Learning_from_Policy-Dependent_Human_Feedback\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/MultiWOZ_-_A_Large-Scale_Multi-Domain_Wizard-of-Oz_Dataset_for_Task-Oriented_Dialogue_Modelling/MultiWOZ_-_A_Large-Scale_Multi-Domain_Wizard-of-Oz_Dataset_for_Task-Oriented_Dialogue_Modelling\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Programming_with_a_Differentiable_Forth_Interpreter/Programming_with_a_Differentiable_Forth_Interpreter\n",
      "/home/devansh/Documents/EMNLP/Parsers/OUT_1/Multilevel_Clustering_via_Wasserstein_Means/Multilevel_Clustering_via_Wasserstein_Means\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-e3ed55f42b17>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/devansh/Documents/EMNLP/Parsers/OUT_1/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'./tok.sh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhashhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
